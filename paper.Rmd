---
title: Comparison of continuous prediction bands for the validation of biomechanical
  curve data
author:
- name: Daniel Koska
  email: daniel.koska@hsw.tu-chemnitz.de
  affiliation: Chemnitz University of Technology, Research Methodology and Data Analysis
    in Biomechanics
  footnote: Corresponding Author
- name: Doris Oriwol
  email: doris.oriwol@partner.kit.edu
  affiliation: Karlsruhe Institute of Technology
- name: Christian Maiwald
  email: christian.maiwald@hsw.tu-chemnitz.de
  affiliation: Chemnitz University of Technology, Research Methodology and Data Analysis
    in Biomechanics
date: "`r format(Sys.time(), '%d %B, %Y')`"
journal: An awesome journal
abstract: |
  Paper als short communication / technical note?

header-includes:
  - \usepackage{amsmath}
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
  pdf_document:
    toc: yes
---

### TODO
<!-- - Exemplarische Paper für die jeweiligen simulierten Datensätze raussuchen -->
<!-- - Umbennung entire curve in "All-or-nothing" (entlehnt von Juul et al.) -->
<!-- - Toleranzintervalle mit reinnehmen? -->
<!-- - ROISLIEN durch Toleranzintervalle ersetzen! -->
- .bib file anlegen
- Begriff spatiotemporal überdenken (wie ist das im Kontext FDA definiert)

<!-- ### TODO read (again) -->
<!-- - White Basics of Estimating Measurement Uncertainty -->
<!-- - Francq B, Govaerts B. How to regress and predict in a Bland-Altman plot? Review and contribution based on tolerance intervals and -->
<!-- correlated-errors-in-variables models. Statist Med. 2016;35:2328-2358. -->
<!-- - Francq Confidence, prediction, and tolerance in linear mixed models -->
<!-- - Vock (2016) -->
<!-- - Parker et al. (2021) https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-01022-x -->
<!-- - Robinson, Vanrenterghem, Pataky (2021) Sample size estimation for biomechanical waveforms: Current practice, recommendations and a comparison to discrete power analysis -->
<!-- - Olshen et al. (1989) Gait analysis and the bootstrap -->
<!-- - Curvewise point and interval summaries for tidy data frames of draws from distributions https://mjskay.github.io/ggdist/reference/curve_interval.html -->
<!-- - Horvath, Kokoszka & Reeder (2013) Estimation of the mean of functional time series and a two-sample problem -->
<!-- - Generell die Kooperationspaper von Hörmann und Kokoszka zu FDA Statistik,insbesondere 'Inference for Functional Data with Applications' (2012) -->
<!-- - Ratkowsky 1990 Handbook of nonlinear regression models -->


```{r echo = FALSE, warning = FALSE, message = FALSE}
library(ggplot2)
# library(boot)

dir.script <- "~/floa/R"
dir.data <- "~/floa/R/examples"

setwd(dir.script)

source("example_data.R")
source("pick_subwise_curves.R")
source("draw_clusters.R")
source("floa_rcb.R")
source("lenhoff_doris.R")
source("floa_point.R")
source("floa_roislien.R")
source("plot_loa.R")
source("get_coverage.R")
source("get_coverage_fraction.R")
source("get_coverage_singlecurve.R")
source("get_coverage_singlecurve_fraction.R")
source("crossval_coverage.R")
source("crossval_coverage_fraction.R")
source("singlecurve_coverage.R")
source("singlecurve_coverage_fraction.R")
source("plot_cov_ver.R")
# source("distance_2_floa.R")
source("estimate_uncertainty_loa.R")
```

# Introduction

Die Beurteilung der Validität biomechanischer Messverfahren erfolgt üblicherweise über den Vergleich eines 'neuen' Messsystems mit einem etablierten. Dabei werden Bewegungen mit zwei Messsystemen simultan aufgezeichnet und Messwerte miteinander verglichen, die theoretisch den gleichen Wert aufweisen sollten. Die statistische Aufbereitung der gemessenen Abweichungen ist bereits bei 0D Punktdaten (z. B. body mass) nicht trivial (Bland & Altman, 1983) und wird zusätzlich erschwert, wenn Messungen als höherdimensionale Daten vorliegen (z. B. 1D Kurvendaten wie EMG-Signale oder COP Verläufe, 2D plantare Druckmatrizen oder 3D bone strain fields). Ein relevanter Anwendungsfall in biomechanischen Bewegungsanalysen sind dabei 1D Zeitreihendaten (Kurven), die zwei wesentliche Unterschiede gegenüber Punktdaten aufweisen: 1. Der Messfehler variiert über der Zeit. 2. Die einzelnen Samplingpunkte der Kurven sind keine bloße Aneinanderreihung unabhängiger Messwerte, sondern lokal abhängige Events (Deluzio & Astephen, 2007; Pataky, 2010). Dieser Umstand ergibt sich aus dem anatomischen Kontext (Viskositätseigenschaften biologischer Gewebe (Fung, 1981), Freiheitsgrade menschlicher Gelenkbewegungen etc.).

In den allermeisten Validierungsstudien werden diese Eigenschaften zugunsten einfacher(er) Modelle vernachlässigt und Kurvendaten auf einzelne diskrete Punkte oder skalare Features (z. B. local extrema, rates of change, or ranges of motion) reduziert. Daraus ergeben sich eine Reihe von Problemen für die Bewertung des Messfehlers: (i) non-stationary error processes are not considered (ii) the validity of statements derived from discrete variables is limited by domain alignment (i. e. phase shift) and the risk of examining points that have little relevance for the system under investigation (Donoghue et al., 2008; Pataky et al., 2008; Richter et al., 2014; Park et al., 2017) (iii) bei der Übertragung punktweiser Statistiken auf alle Samplingpunkte lokal korrelierter Kurven ist zu erwarten, dass die zufällige Fehlerkomponente unterschätzt wird, da der (nonzero) covariance term of adjacent sampling points nicht berücksichtigt wird (Olea & Plagborg-Moeller, 2018; Lenhoff et al., 1999). Die üblicherweise zur Korrektur beim multiplen Testen eingesetzten Korrekturverfahren zur Anpassung des alpha levels (Hochberg & , 1987) führen aufgrund der hohen Anzahl an Datenpunkten pro Kurve ($t \le 100$) zu sehr konservativen Schätzungen weshalb dieses Vorgehen hier nicht zielführend ist. Ein besserer Ansatz ist es Kurven direkt als zusammenhängende Objekte zu betrachten.

Sutherland, Olshen, Biden & Wyatt (1988, 1989) (BOOT) haben für Gelenkwinkeldaten im Kontext von Ganganalysen Ende der 1980er Jahre eine Methode vorgestellt, bei der Kurvendaten mithilfe eines random (Fourier) coefficient Regressionsmodells approximiert werden und aus den so gebildeten funktionalen Objekte durch Bootstrapping Prädiktionsbänder für normales Gehen gebildet werden. Lenhoff et al. (1999) illustrated the same method on a generic gait analysis data set (comprised of joint angle curves) and compared it to pointwise Gaussian intervals. By means of a leave-one out cross validation they found that the Sutherland prediction bands provide appropriate coverage for continuous curve gait data (86% coverage at 90% nominal coverage level) while pointwise Gaussian bands are shown to provide inadequate coverage (54%). Røislien et al. (2012) haben einen Ansatz präsentiert, mit dem die Methode von Bland & Altman (1983) für kontinuierliche Daten erweitert wird. Der Ansatz von Bland & Altman ist die am weitesten verbreitete Methode in Methodenvergleichen (Ludbrook, 2010) und verwendet die Differenzen zwischen zwei Messmethoden für die Konstruktion von Limits Agreement (LoA).

Das vorliegende Paper strebt eine systematische Validierung verschiedener Methoden zur Konstruktion kontinuierlicher Fehlerintervalle bei Methodenvergleichen an. Dazu sollen drei verschiedene Methoden anhand simulierter und realer Datensätze charakteristischer glatter Kurven biomechanischer Messysteme (Gelenkwinkelverläufe von zwei Messsystemen) verglichen werden: (1) punktweise Bland and Altman LoA, (2) LoA nach Roislien et al. und (3) gebootstrappte funktionale Prädiktionsbänder (Sutherland, Olshen, Biden & Wyatt (1988, 1989)). Da sowohl die Intervalle von Sutherland als auch Roislien im Wesentlichen Prädiktionsintervalle repräsentieren, soll der Methodenvergleich exemplarisch am Beispiel kontinuierlicher Prädiktionsbänder vollzogen werden. Die Methode lässt sich jedoch prinzipiell auch auf andere Intervallmethoden wie Konfidenz- oder Toleranzintervalle übertragen. Zur Beurteilung der Intervallgüte werden die qualitative Verläufe der Intervallgrenzen der jeweiligen Verfahren gegen die tatsächlichen Differenzen geplottet und die entsprechenden coverage properties berechnet. Für die Beurteilung der Intervallgüte wird im Rahmen einer leave-one out cross validation die Unsicherheit in den berechneten LoA angegeben.

Obwohl wir in der Arbeit bei Weitem nicht alle Anwendungsfälle (Methoden, Intervalle, Datensätze) abdecken können, hoffen wir einen Impuls für die breitere Anwendung kontinuierlicher Methoden im Rahmen biomechanischer Validierungsstudien setzen zu können. In diesem Sinne stellen wir auch den zugehörigen R Code im Anhang zur freien Verfügung.

# Methods

### Data sets

Für den Vergleich der Methoden wurden vier Datensätze (drei simulierte und ein realer) verwendet. Jeder dieser Datensätze enthält jeweils $N = 220$ Kurven der Länge $T = 101$ Datenpunkte aus $M = 2$ Messsystemen. Das entspricht in jedem Datensatz $D = 110$ Differenzkurven:

\begin{equation}
\tag{1}
\sum D_{ij} = \sum_{i=1}^{I} \sum_{j=1}^{J} Y_{ij} - X_{ij} = 110
\label{eq:mean}
\end{equation}

X und Y sind (I x J) Matrizen der beiden Messsysteme, mit $I = 11$ Probanden und $J = 10$ wiederholten Kurven pro Proband. Alle simulierten Datensätze wurden als glatte Kurven, ähnlich Gelenkwinkelverläufen, mit dem gleichen Grundmodell generiert. Dazu wurden für jedes Messsystem zwei ähnliche Sinusfunktionen überlagert:

$$
X_{ij} = (offset_{m}) + f_{1}(t) + f_{2}(t),\\Y_{ij}(t) = (offset_{m}) + f_{3}(t) + f_{4}(t)
$$
mit

$$
f_{1, 3}(t) = Asin(Bt)^{c + 3}
$$
und

$$
f_{2, 4}(t) = Asin(Bt)
$$
$A$, $B$ sind Zufallsvariablen mit unterschiedlichen Verteilungseigenschaften (normal, uniform, Weibull) über deren Parameter systematische und zufällige Unterschiede zwischen Probanden (between subject variation), Schritten (within subject variation) und Messystemen modelliert werden. $c$ ist eine Konstante ($c = 2$). Zudem wurden - je nach Datensatz - unterschiedliche Offsets als normalverteilte Zufallsvariablen mit variierenden $\mu$ und $\sigma$ simuliert:

$$
offset_{m} \sim N(\mu_{i}, \sigma=0.05)
$$
Im Sinne der Reproduzierbarkeit wurden alle Zufallsvariablen mit einem random seed initialisiert. Der Code für die Generierung der Kurven kann im Anhang im Detail nachvollzogen werden.

```{r echo = FALSE, warning = FALSE, message = FALSE}
data <- example_data(dat = "smooth_realistic", dir.data)
data.single.mc <- subset(data, device == "MC")
data.single.imu <- subset(data, device == "IMU")

PLOT.1 <- ggplot(data = data.single.mc, aes(x = frame, y = value, group = strideID)) +
  geom_line() +
  scale_color_grey(start = 0.6, end = 0.9) +
  geom_line(data = data.single.imu, aes(x = frame, y = value, group = strideID, colour = as.factor(subjectID)), alpha = 0.3) +
  labs(x = "Time-normalized signal [%]", y = "Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "none")


data <- example_data(dat = "non_gaussian", dir.data)
data.single.mc <- subset(data, device == "MC")
data.single.imu <- subset(data, device == "IMU")

PLOT.2 <- ggplot(data = data.single.mc, aes(x = frame, y = value, group = strideID)) +
  geom_line() +
  scale_color_grey(start = 0.6, end = 0.9) +
  geom_line(data = data.single.imu, aes(x = frame, y = value, group = strideID, colour = as.factor(subjectID)), alpha = 0.3) +
  labs(x = "Time-normalized signal [%]", y = "Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "none")


data <- example_data(dat = "shift", dir.data)
data.single.mc <- subset(data, device == "MC")
data.single.imu <- subset(data, device == "IMU")

PLOT.3 <- ggplot(data = data.single.mc, aes(x = frame, y = value, group = strideID)) +
  geom_line() +
  scale_color_grey(start = 0.6, end = 0.9) +
  geom_line(data = data.single.imu, aes(x = frame, y = value, group = strideID, colour = as.factor(subjectID)), alpha = 0.3) +
  labs(x = "Time-normalized signal [%]", y = "Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "none")


data <- example_data(dat = "imu_mc", dir.data)
data.single.mc <- subset(data, device == "MC")
data.single.imu <- subset(data, device == "IMU")

PLOT.4 <- ggplot(data = data.single.mc, aes(x = frame, y = value, group = strideID)) +
  geom_line() +
  scale_color_grey(start = 0.6, end = 0.9) +
  geom_line(data = data.single.imu, aes(x = frame, y = value, group = strideID, colour = as.factor(subjectID)), alpha = 0.3) +
  labs(x = "Time-normalized signal [%]", y = "Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "none")
```


```{r echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Figure 1: Kurvenverläufe in den jeweiligen Datensätzen (A - D). Schwarze Kurven im Hintergrund sind die Werte des Referenzsystems."}
PLOT <- ggpubr::ggarrange(PLOT.1, PLOT.2, PLOT.3, PLOT.4,
                          labels = c("A", "B", "C", "D"),
                          ncol = 2,
                          nrow = 2)
PLOT
```

Fig. 1 stellt die originalen Kurven beider Messsysteme in den vier verwendeten Datensätzen (A - D) dar:

* Datensatz A : Simulated curves with Gaussian error model ($\epsilon_{i} \sim N (0, \sigma_{i}^2)$).

Die Daten repräsentieren den Fall, dass die Kurven zweier Messsysteme qualitativ ähnlich sind und kein relevanter Bias vorliegt.

* Datensatz B : Simulated curves with non-Gaussian erros and heteroskedasticity

Der Skalierungsparameter des zweiten Messsystems ist als normalverteilte Zufallsvariable mit Weibull-verteiltem Mittelwert modelliert ($\epsilon_{i} \sim N(\mu \sim Wei(\gamma = 1.5,\alpha  = 1), \sigma_{i})$). Wie in (A) liegt kein Bias vor.

Solche Daten liegen vor, wenn mindestens eines der Messsysteme Kurven produziert, die qualitativ und quantitativ deutlich vom wahren Wert abweichen (hier: Messsystem 2, grau). In diesem Fall sind elementare Modellvoraussetzungen für parametrische Verfahren wie Bland and Altman erheblich verletzt.

* Datensatz C : Simulated curves curves with Gaussian error model and phase shift in x-axis direction.

Die Kurven wurden mit dem selben Modell wie in (A) erstellt, aber die Kurven von Messsystem 2 (grau) sind auf der x-Achse verschoben. Auch hier sind Modellvoraussetzungen erheblich verletzt, die Differenzen weisen aber eine andere Verteilung auf als in Modell (B). In der Praxis treten vergleichbare Kurvenverläufe auf, wenn die Messung eines Systems in ihrem zeitlichen Verlauf in irgendeiner Weise systematisch beeinflusst wird, z. B. wenn die Messsysteme infolge der Platzierung am Körper unterschiedliche Bewegungen aufzeichnen, oder durch Filterartefakte.

* Datensatz D : Reale Messdaten aus der Validierung einer inertialen Messeinheit (IMU)

Real-world hip joint angle curves from healthy subjects walking at 6 km/h on a treadmill without gradient recorded simultaneously using an optical motion capture system (MC) and IMU. Die Kurven unterscheiden sich qualitativ und in der absoluten Ausprägung der Differenzen.


Die Größe der Datensätze wurde bewusst klein gehalten, um dem typischen Stichprobenumfang vieler Validierungsstudien zu entsprechen. Die Kurven korrespondieren nicht mit realen Signalen und wurden teilweise bewusst überspitzt konstruiert um den Einfluss häufig auftretender Fehlercharakteristika (nicht Gauss'sche Fehler, Heteroskedastizität) auf das Verhalten der Bänder hervorzuheben.

Der Code zum Erstellen der Kurven findet sich im Anhang und auf Github als R Code und txt Dateien.

### Calculation methods

Die untersuchten Prädiktionsbänder wurden ausschließlich anhand der gebildeten Differenzkurven $D$ gebildet um die Vergleichbarkeit der Methoden zu gewährleisten. Prädiktionsbänder wurden mit drei unterschiedlichen Verfahren berechnet:

* 1. POINT : Pointwise continuous LoA according to Bland & Altman (1999, 2007)

Für alle $t = 101$ Punkte wurden jeweils über alle $D$ Kurven LoA berechnet. Bei erfüllten Modellvoraussetzungen (unabhängige Kurven, normalverteilte Differenzen, Homoskedastizität), kann erwartet werden, dass 95% der Differenzen im Intervall mean difference $\pm$ 1.96 $*$ standard deviation of the differences liegen. Wir verwenden in der vorliegenden Arbeit ein komplexeres Modell für wiederholte Messungen, in dem sich der wahre Wert über jedes Differenzpaar ändert (Bland & Altman, 1999). Das Modell beschreibt die Differenz zwischen zwei Messsystemen als Summe der mittleren Differenz ($\overline{d}$) und zweier Varianzkomponenten (between ($\sigma^2_{db}$), within ($\sigma^2_{dw}$)):
<!-- Auch wenn hier jeweils die gleiche Anzahl Kurven für jedes Messsystem vorliegt, erlaubt die verwendete Formel die Übertragung auf den unbalancierten Fall. -->

$$
LoA = D_{ij} = \overline{d} + \sqrt{\sigma^2_{db} + \sigma^2_{dw}}
$$
Die beiden Varianzkomponenten können mithilfe einer einfaktoriellen Varianzanalyse bestimmt werden. \sigma^2_{dw} kann als residual mean square ($MS_{w}$) direkt aus dem ANOVA table abgelesen werden. \sigma^2_{db} berechnet sich aus der Differenz aus between-subject mean squares und $MS_{w}$, geteilt durch einen Term, der die Anzahl der $i$ Probanden und $j$ Kurven berücksichtigt. Wenn für alle Probanden die gleiche Anzahl an Datenpunkten vorliegt (wie im vorliegenden Fall), reduziert sich dieser Term auf die Anzahl der Datenpunkte (Kurven) pro Proband ($j = 10$):

$$
\sigma^2_{db} = \frac{(MS_{b} - MS_{w})}{j}
$$
Für weiterführende Informationen zur Berechnung (z. B. bei ungleicher Anzahl Observationen pro Proband) siehe Bland & Altman (1999, 2007) sowie die zugehörige Implementierung als R Code im Anhang.

* 2. ROISLIEN : Functional limits of agreement (FLoA) according to Roislien et al. (2012)

Die Methode von Røislien et al. (2012) wurde als Erweiterung der Methode von Bland & Altman (1983) für kontinuierliche Differenzen ($d(t)$) entwickelt. Roislien et al. approximieren die Kurven im Datensatz daher zunächst mithilfe elementarer trigonometrischer Funktionen. Die Berechnung der Modellparameter ($\overline{d}$, $\sigma$) erfolgt im Anschluss allerdings - genau wie in POINT - separat für jeden Punkt der Kurve. Daher macht es in der praktischen Umsetzung de facto keinen Unterschied ob die originalen (diskreten) oder funktionalen Kurven verwendet werden. Wir verzichten daher im Rahmen dieses Papers auf die Repräsentation der Kurven als Funktionen. Das Modell ist dennoch interessant weil gegenüber der Variante in POINT (i) keine wiederholten Kurven verwendet werden, sondern nur je eine Kurve pro Proband um die Modellvoraussetzung der Unabhängigkeit der Kurven nicht zu verletzen und (ii) die (punktweise) Berechnung der LoA für diese $j = i$ Kurven mithilfe des minimalen Bland & Altman Modells erfolgt ($LoA = d(t) \pm 1.96SD(t)$), wobei $\overline{d}(t)$ die kontinuierliche mean difference bezeichnet. 

* 3. BOOT : Boostrapped functional prediction bands according Sutherland et al. (1988), Olshen et al. (1989) and Lenhoff et al. (1999)

Die Methode ist die einzige der vorgestellten Methoden, die vollständig funktional arbeitet, d. h. die Konstruktion der Prädiktionsbänder findet nicht punktweise, sondern auf Grundlage ganzer Kurven statt.

Bootstrapping ist ein nicht-parametrisches Verfahren und kommt daher ohne Annahmen zur Verteilung der Differenzen aus.

Im ersten Schritt des Verfahrens werden alle $N$ gemessenen Kurven mithilfe von Fourier-Reihen als Funktionen approximiert:

$$
f_{n}(t) = \mu_{n} + \sum_{k=1}^K(\alpha_{nk}cos(\frac{2\pi kt}{T}) + \beta_{nk} sin(\frac{2\pi kt}{T}))
$$
Die Anzahl der Fourier-Basisfunktionen $K$ ist dabei so zu wählen, dass die Kurven bestmöglich angenähert werden und keine ungewollte Glättungseffekte entstehen. In der vorliegenden Arbeit wurde großzügig $K = 50$ gewählt. Die Koeffizienten ($\mu_{n}, \alpha_{n1}, \beta_{n1}, ..., \alpha_{nK}, \beta_{nK}$) werden durch die Methode der kleinsten Quadrate bestimmt. 

asserts that the curve starts and ends at the same height.
<!-- Für das weitere Vorgehen ist dabei wichtig, dass $\mu$ für alle Kurven 0 sein muss, da die Standardabweichungskurve der Kurvenschar sonst einen Offset aufweist. -->

Die Koeffizienten werden in einer Matrix $M$ mit den Dimensionen $N$ (Zeilen) und $2K+1$ zusammengefasst. Aus dieser Matrix werden durch Bootstrapping $B = 400$ mal $N$ Kurven aus $M$ mit Zurücklegen gezogen, für die jeweils die mittlere Kurve $\hat{f^b}(t)$ und Kovarianzmatrix $\hat{\sigma_{\hat{f^b}(t)}}$ bestimmt werden.

Im Mittel über alle Bootstrapiterationen lässt sich daraus der Anteil der Kurven bestimmen, deren maximale standardisierte Abweichung vom Bootstrap-Mittel ($\hat{f^b}(t)$) kleiner gleich $C_{p}$ beträgt.

$$
\frac{1}{B} \sum_{b=1}^B [\frac{1}{N} \sum_{n=1}^N I(\max_{t} (\frac{|\hat{f}_{n}(t) - \hat{f^b}(t)|}{\hat{\sigma}_{f(t)}} \le C_{p})]
$$
wobei $I(E)$ eine Matrix ist die Werte von entweder 0 ($E$ tritt nicht auf) oder 1 ($E$ tritt auf) annimmt.



$C_{p}$ muss dabei so optimiert werden, dass es der gewünschten coverage probability des Prädiktionsbandes $P = 1- \alpha$ (hier: $\alpha=0.05$) entspricht. Damit ist berechnet sich das Prädiktionsband als:

$$
\hat{f}(t) \pm C_{p} \hat{\sigma}_{f(t)}
$$

```{r echo = FALSE, warning = FALSE, message = FALSE}
# Wrapper function for example data sets. Function arguments:
#
# (* Empirical validation data: "imu_mc")
# * Smooth, wave data (normal error, constant variance, no trend): "smooth"
# * Smooth wave data with nonlinear trend (constant variance): "smooth_trend"
# * Data with non-gaussian (Weibull distributed) error (no trend): "non_gaussian"
# * Data with shock peaks (no bias, no trend): "shock"
data <- example_data(dat = "smooth", dir.data)

# Mean and SD are calculated across all strides (and subjects).
# No bootstrap or other resampling strategies are applied.
floa.point <- floa_point(data)
```


### Leave-one out cross validation

Um die coverage Performance der untersuchten Methoden zu bewerten, wurden die jeweiligen Intervalle im leave-one-out Verfahren kreuzvalidiert. Dazu wird jeweils eine Kurve vom Datensatz entfernt und die Intervalle anhand der übrigen Kurven berechnet. Dieser Vorgang wird für jede der $N$ Kurven eines Datensatzes wiederholt. Der Anteil der vorgehaltenen Kurven, die in den Bändern enthalten sind, wird mit zwei verschiedenen Kennwerten beschrieben:

* Percentage of entirely covered curves (all points within the limits)

* Mean (SD) of curve points within the respective FLoA: The fraction of points along a curve within the limits is calculated and averaged across all curves of a subject.

### LoA uncertainty estimation

Um die Schwankung der Intervallgrenzen über wiederholte Berechnungen hinweg zu veranschaulichen, wurden für alle drei Verfahren Unsicherheitsbänder durch gebootstrapped ($B = 400$). Die Unsicherheit entsteht durch wiederholtes Ziehen mit Zurücklegen im Rahmen des Bootstrapverfahrens (BOOT) bzw. die jeweils unterschiedlichen gezogenen Einzelkurven (ROISLIEN).

Im Falle der POINT Intervalle werden alle Kurven eines Datensatzes verwendet, weshalb keine Schwankung der Intervallgrenzen auftritt. Verschiedene Autoren schlagen jedoch Konfidenzintervalle (KI) als Erweiterung ihres ursprünglichen Ansatzes vor, um den sampling error insbesondere kleiner Stichproben (Bland & Altman, 1986; Hamilton & Stamey, 2007; Giavarina, 2015) zu berücksichtigen. Bland & Altman (1986) schlagen die folgende Formel vor (95% CI für 95% LoA):

$$
(\overline{d} \pm z_{0.975}SD) \pm t_{0.975, n-1}SD\sqrt{\frac{1}{N} + \frac{z^2_{0.975}}{2(N-1)}}
$$
Quelle? Wo steht die Formel drin?

mit $z_{0.975} = 1.96$.

<!-- schätzen den Standardfehler der Differenzen auf ungefähr $\sqrt{3*s² / c}$. -->

Für die Berechnung von Konfidenzintervallen wird noch das geeignete Quantil der t-Verteilung mit n − 1 Freiheitsgraden benötigt. Das Konfidenzintervall reicht dann vom oberen/unteren Limit minus t$*$Standardfehler bis zum oberen/unteren Limit plus t$*$Standardfehler. Im vorliegenden Paper wurden 95% Konfidenzintervalle gerechnet.

# Results

### Functional limits of agreement

```{r echo = FALSE, warning = FALSE, message = FALSE}
n.boot <- 30
```

#### Simulated curves with Gaussian error model (A)

```{r echo = FALSE, warning = FALSE, message = FALSE}
data <- example_data(dat = "smooth_realistic", dir.data)

floa.point <- floa_point(data)
floa.roislien <- floa_roislien(data)
floa.lenhoff.pred  <- floa_lenhoff(data,
                                   k_reihe = 50,
                                   n.boot = n.boot,
                                   band = "prediction",
                                   cp.begin = 0,
                                   alpha = 0.05)

plot_loa(data, floa.point, floa.roislien, floa.lenhoff.pred, ylim = c(-5, 5))
```

#### Simulated curves with non-normal, heteroskedastic differences (B)

```{r echo = FALSE, warning = FALSE, message = FALSE}
# data <- example_data(dat = "non_gaussian", dir.data)
# 
# floa.point <- floa_point(data)
# floa.roislien <- floa_roislien(data)
# floa.lenhoff.pred  <- floa_lenhoff(data,
#                                    k_reihe = 50,
#                                    n.boot = n.boot,
#                                    band = "prediction",
#                                    cp.begin = 0,
#                                    alpha = 0.05)
# 
# plot_loa(data, floa.point, floa.roislien, floa.lenhoff.pred, ylim = c(-10, 10))
```

#### Simulated curves curves with Gaussian error model created and phase shift in x-axis direction (C)

```{r echo = FALSE, warning = FALSE, message = FALSE}
# data <- example_data(dat = "shift", dir.data)
# 
# floa.point <- floa_point(data)
# floa.roislien <- floa_roislien(data)
# floa.lenhoff.pred  <- floa_lenhoff(data,
#                                    k_reihe = 50,
#                                    n.boot = n.boot,
#                                    band = "prediction",
#                                    cp.begin = 0,
#                                    alpha = 0.05)
# 
# plot_loa(data, floa.point, floa.roislien, floa.lenhoff.pred, ylim = c(-5, 5))
```

#### Real-world validation data (hip joint angles)

```{r echo = FALSE, warning = FALSE, message = FALSE}
# data <- example_data(dat = "imu_mc", dir.data)
# 
# floa.point <- floa_point(data)
# floa.roislien <- floa_roislien(data)
# floa.lenhoff.pred  <- floa_lenhoff(data,
#                                    k_reihe = 50,
#                                    n.boot = n.boot,
#                                    band = "prediction",
#                                    cp.begin = 0,
#                                    alpha = 0.05)
# 
# plot_loa(data, floa.point, floa.roislien, floa.lenhoff.pred, ylim = c(-15, 15))
```

### Leave-one (curve) out cross validation

#### Realistic smooth wave data (constant variance, no trend)
a. Coverage of the entire curve
```{r echo = FALSE, warning = FALSE, message = FALSE}
# data <- example_data(dat = "smooth_realistic", dir.data)
# 
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)
# 
# # Calculate percent from counts
# calculate_percent <- function(data) {
#   percentage <- (sum(data) / length(data))
#   percentage <- round(percentage, digits = 2)
# }
# 
# covered.curves.percent <- apply(cover.cross.singlecurve, 2, calculate_percent)
# covered.curves.percent <- data.frame(t(covered.curves.percent))
# colnames(covered.curves.percent) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(covered.curves.percent, caption = "Percentages of entirely covered curves")
```

b. Mean (SD) of covered curve points
```{r echo = FALSE, warning = FALSE, message = FALSE}
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.fraction.singlecurve <- singlecurve_coverage_fraction(data, n.boot)
# 
# cover.cross.mean.sd <- rbind(round(colMeans(cover.cross.fraction.singlecurve), 2),
#              round(apply(cover.cross.fraction.singlecurve, 2, sd), 2)
# )
# colnames(cover.cross.mean.sd) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(cover.cross.mean.sd, caption = "Mean (top) and SD of covered points across the curve")
# 
# # # Display as boxplots across methods
# # plot_cov_ver(cover.cross.fraction.singlecurve)
```

<!-- c. Average distance to the outer point of the curve set -->
<!-- ```{r echo = FALSE, warning = FALSE, message = FALSE} -->
<!-- floa <- floa_rcb(data, n.boot, ver = "v2") -->
<!-- floa.point <- floa_point(data) -->
<!-- floa.roislien <- floa_roislien(data) -->

<!-- dist.all <- data.frame(distance_2_floa(data, floa)$upr.dist, -->
<!--                        distance_2_floa(data, floa)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.point)$upr.dist, -->
<!--                        distance_2_floa(data, floa.point)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$upr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$lwr.dist -->
<!--                        ) -->

<!-- colnames(dist.all) <- c("floa.up", "floa.lw", "point.up", "point.lw", "roislien.up", "roislien.lw") -->

<!-- boxplot(dist.all, ylab = "floa boundary - curve maximum") -->
<!-- ``` -->

c. Uncertainty in LoA (95% percentile intervals)
```{r echo = FALSE, warning = FALSE, message = FALSE}
estimate_uncertainty_loa(data, n.boot)
```

#### Smooth, wave data (normal error, constant variance, no trend)
a. Coverage of the entire curve
```{r echo = FALSE, warning = FALSE, message = FALSE}
# data <- example_data(dat = "smooth", dir.data)
# 
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)
# 
# # Calculate percent from counts
# calculate_percent <- function(data) {
#   percentage <- (sum(data) / length(data))
#   percentage <- round(percentage, digits = 2)
# }
# 
# covered.curves.percent <- apply(cover.cross.singlecurve, 2, calculate_percent)
# covered.curves.percent <- data.frame(t(covered.curves.percent))
# colnames(covered.curves.percent) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(covered.curves.percent, caption = "Percentages of entirely covered curves")
```

b. Mean (SD) of covered curve points
```{r echo = FALSE, warning = FALSE, message = FALSE}
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.fraction.singlecurve <- singlecurve_coverage_fraction(data, n.boot)
# 
# cover.cross.mean.sd <- rbind(round(colMeans(cover.cross.fraction.singlecurve), 2),
#              round(apply(cover.cross.fraction.singlecurve, 2, sd), 2)
# )
# colnames(cover.cross.mean.sd) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(cover.cross.mean.sd, caption = "Mean (top) and SD of covered points across the curve")
# 
# # # Display as boxplots across methods
# # plot_cov_ver(cover.cross.fraction.singlecurve)
```

<!-- c. Average distance to the outer point of the curve set -->
<!-- ```{r echo = FALSE, warning = FALSE, message = FALSE} -->
<!-- floa <- floa_rcb(data, n.boot, ver = "v2") -->
<!-- floa.point <- floa_point(data) -->
<!-- floa.roislien <- floa_roislien(data) -->

<!-- dist.all <- data.frame(distance_2_floa(data, floa)$upr.dist, -->
<!--                        distance_2_floa(data, floa)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.point)$upr.dist, -->
<!--                        distance_2_floa(data, floa.point)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$upr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$lwr.dist -->
<!--                        ) -->

<!-- colnames(dist.all) <- c("floa.up", "floa.lw", "point.up", "point.lw", "roislien.up", "roislien.lw") -->

<!-- boxplot(dist.all, ylab = "floa boundary - curve maximum") -->
<!-- ``` -->

c. Uncertainty in LoA (95% percentile intervals)
```{r echo = FALSE, warning = FALSE, message = FALSE}
# estimate_uncertainty_loa(data, n.boot)
```

#### Curves with nonlinear trend (constant variance)

a. Coverage of the entire curve
```{r echo = FALSE, warning = FALSE, message = FALSE}
# data <- example_data(dat = "smooth_trend", dir.data)
# 
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)
# 
# # Calculate percent from counts
# calculate_percent <- function(data) {
#   percentage <- (sum(data) / length(data))
#   percentage <- round(percentage, digits = 2)
# }
# 
# covered.curves.percent <- apply(cover.cross.singlecurve, 2, calculate_percent)
# covered.curves.percent <- data.frame(t(covered.curves.percent))
# colnames(covered.curves.percent) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(covered.curves.percent, caption = "Percentages of entire covered curves")
```

b. Mean (SD) of covered curve points
```{r echo = FALSE, warning = FALSE, message = FALSE}
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.fraction.singlecurve <- singlecurve_coverage_fraction(data, n.boot)
# 
# cover.cross.mean.sd <- rbind(round(colMeans(cover.cross.fraction.singlecurve), 2),
#              round(apply(cover.cross.fraction.singlecurve, 2, sd), 2)
# )
# colnames(cover.cross.mean.sd) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(cover.cross.mean.sd, caption = "Mean (top) and SD of covered points across the curve")
```

<!-- c. Average distance to the outer point of the curve set -->
<!-- ```{r echo = FALSE, warning = FALSE, message = FALSE} -->
<!-- floa <- floa_rcb(data, n.boot, ver = "v2") -->
<!-- floa.point <- floa_point(data) -->
<!-- floa.roislien <- floa_roislien(data) -->

<!-- dist.all <- data.frame(distance_2_floa(data, floa)$upr.dist, -->
<!--                        distance_2_floa(data, floa)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.point)$upr.dist, -->
<!--                        distance_2_floa(data, floa.point)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$upr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$lwr.dist -->
<!--                        ) -->

<!-- colnames(dist.all) <- c("floa.up", "floa.lw", "point.up", "point.lw", "roislien.up", "roislien.lw") -->

<!-- boxplot(dist.all, ylab = "floa boundary - curve maximum") -->
<!-- ``` -->

c. Uncertainty in LoA (95% percentile intervals)
```{r echo = FALSE, warning = FALSE, message = FALSE}
# estimate_uncertainty_loa(data, n.boot)
```

#### Curves with non-gaussian (Weibull distributed) error (no trend)
a. Coverage of the entire curve
```{r echo = FALSE, warning = FALSE, message = FALSE}
# data <- example_data(dat = "non_gaussian", dir.data)
# 
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)
# 
# # Calculate percent from counts
# calculate_percent <- function(data) {
#   percentage <- (sum(data) / length(data))
#   percentage <- round(percentage, digits = 2)
# }
# 
# covered.curves.percent <- apply(cover.cross.singlecurve, 2, calculate_percent)
# covered.curves.percent <- data.frame(t(covered.curves.percent))
# colnames(covered.curves.percent) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(covered.curves.percent, caption = "Percentages of entire covered curves")
```

b. Mean (SD) of covered curve points
```{r echo = FALSE, warning = FALSE, message = FALSE}
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.fraction.singlecurve <- singlecurve_coverage_fraction(data, n.boot)
# 
# cover.cross.mean.sd <- rbind(round(colMeans(cover.cross.fraction.singlecurve), 2),
#              round(apply(cover.cross.fraction.singlecurve, 2, sd), 2)
# )
# colnames(cover.cross.mean.sd) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(cover.cross.mean.sd, caption = "Mean (top) and SD of covered points across the curve")
# 
# # # Display as boxplots acroos methods
# # plot_cov_ver(cover.cross.fraction.singlecurve)
```

<!-- c. Average distance to the outer point of the curve set -->
<!-- ```{r echo = FALSE, warning = FALSE, message = FALSE} -->
<!-- floa <- floa_rcb(data, n.boot, ver = "v2") -->
<!-- floa.point <- floa_point(data) -->
<!-- floa.roislien <- floa_roislien(data) -->

<!-- dist.all <- data.frame(distance_2_floa(data, floa)$upr.dist, -->
<!--                        distance_2_floa(data, floa)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.point)$upr.dist, -->
<!--                        distance_2_floa(data, floa.point)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$upr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$lwr.dist -->
<!--                        ) -->

<!-- colnames(dist.all) <- c("floa.up", "floa.lw", "point.up", "point.lw", "roislien.up", "roislien.lw") -->

<!-- boxplot(dist.all, ylab = "floa boundary - curve maximum") -->
<!-- ``` -->

c. Uncertainty in LoA (95% percentile intervals)
```{r echo = FALSE, warning = FALSE, message = FALSE}
# estimate_uncertainty_loa(data, n.boot)
```

#### Curves phase shifted in x-axis direction
a. Coverage of the entire curve
```{r echo = FALSE, warning = FALSE, message = FALSE}
# data <- example_data(dat = "shift", dir.data)
# 
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)
# 
# # Calculate percent from counts
# calculate_percent <- function(data) {
#   percentage <- (sum(data) / length(data))
#   percentage <- round(percentage, digits = 2)
# }
# 
# covered.curves.percent <- apply(cover.cross.singlecurve, 2, calculate_percent)
# covered.curves.percent <- data.frame(t(covered.curves.percent))
# colnames(covered.curves.percent) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(covered.curves.percent, caption = "Percentages of entire covered curves")
```

b. Mean (SD) of covered curve points
```{r echo = FALSE, warning = FALSE, message = FALSE}
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.fraction.singlecurve <- singlecurve_coverage_fraction(data, n.boot)
# 
# cover.cross.mean.sd <- rbind(round(colMeans(cover.cross.fraction.singlecurve), 2),
#              round(apply(cover.cross.fraction.singlecurve, 2, sd), 2)
# )
# colnames(cover.cross.mean.sd) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(cover.cross.mean.sd, caption = "Mean (top) and SD of covered points across the curve")
# 
# # # Display as boxplots acroos methods
# # plot_cov_ver(cover.cross.fraction.singlecurve)
```

<!-- c. Average distance to the outer point of the curve set -->
<!-- ```{r echo = FALSE, warning = FALSE, message = FALSE} -->
<!-- floa <- floa_rcb(data, n.boot, ver = "v2") -->
<!-- floa.point <- floa_point(data) -->
<!-- floa.roislien <- floa_roislien(data) -->

<!-- dist.all <- data.frame(distance_2_floa(data, floa)$upr.dist, -->
<!--                        distance_2_floa(data, floa)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.point)$upr.dist, -->
<!--                        distance_2_floa(data, floa.point)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$upr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$lwr.dist -->
<!--                        ) -->

<!-- colnames(dist.all) <- c("floa.up", "floa.lw", "point.up", "point.lw", "roislien.up", "roislien.lw") -->

<!-- boxplot(dist.all, ylab = "floa boundary - curve maximum") -->
<!-- ``` -->

c. Uncertainty in LoA (95% percentile intervals)
```{r echo = FALSE, warning = FALSE, message = FALSE}
# estimate_uncertainty_loa(data, n.boot)
```

#### Real-world validation data
a. Coverage of the entire curve
```{r echo = FALSE, warning = FALSE, message = FALSE}
# data <- example_data(dat = "imu_mc", dir.data)
# 
# # Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)
# 
# # Calculate percent from counts
# calculate_percent <- function(data) {
#   percentage <- (sum(data) / length(data))
#   percentage <- round(percentage, digits = 2)
# }
# 
# covered.curves.percent <- apply(cover.cross.singlecurve, 2, calculate_percent)
# covered.curves.percent <- data.frame(t(covered.curves.percent))
# colnames(covered.curves.percent) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(covered.curves.percent, caption = "Percentages of entire covered curves")
```

b. Mean (SD) of covered curve points
```{r echo = FALSE, warning = FALSE, message = FALSE}
# Leave-one curve out approach
# # ------------------------------------------------------------------------------
# cover.cross.fraction.singlecurve <- singlecurve_coverage_fraction(data, n.boot)
# 
# cover.cross.mean.sd <- rbind(round(colMeans(cover.cross.fraction.singlecurve), 2),
#              round(apply(cover.cross.fraction.singlecurve, 2, sd), 2)
# )
# colnames(cover.cross.mean.sd) <- c("Point", "Roislien", "Lenhoff")
# 
# knitr::kable(cover.cross.mean.sd, caption = "Mean (top) and SD of covered points across the curve")
# 
# # # Display as boxplots acroos methods
# # plot_cov_ver(cover.cross.fraction.singlecurve)
```

<!-- c. Average distance to the outer point of the curve set -->
<!-- ```{r echo = FALSE, warning = FALSE, message = FALSE} -->
<!-- floa <- floa_rcb(data, n.boot, ver = "v2") -->
<!-- floa.point <- floa_point(data) -->
<!-- floa.roislien <- floa_roislien(data) -->

<!-- dist.all <- data.frame(distance_2_floa(data, floa)$upr.dist, -->
<!--                        distance_2_floa(data, floa)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.point)$upr.dist, -->
<!--                        distance_2_floa(data, floa.point)$lwr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$upr.dist, -->
<!--                        distance_2_floa(data, floa.roislien)$lwr.dist -->
<!--                        ) -->

<!-- colnames(dist.all) <- c("floa.up", "floa.lw", "point.up", "point.lw", "roislien.up", "roislien.lw") -->

<!-- boxplot(dist.all, ylab = "floa boundary - curve maximum") -->
<!-- ``` -->

c. Uncertainty in LoA (95% percentile intervals)
```{r echo = FALSE, warning = FALSE, message = FALSE}
# estimate_uncertainty_loa(data, n.boot)
```



# Discussion

Punktweise FLoA unterrepräsentieren den Messfehler sind aber ganz ok. Allerdings gilt es zu konstatieren, dass die korrekte Berechnung (ANOVA-Varianzanteile, Konfidenzintervalle) auch nicht unbedingt trivial ausfällt.

FLoA Roislien tendieren dazu zu weit auszufallen (den Messfehler zu überrepräsentieren)

Im Allgemeinen sind Prädiktionsintervalle überall dort von Interesse, wo neue Messwerte gegen normative Daten (z. B. aus einer Referenzdatenbank) verglichen werden. Wenn die Abweichung ein bestimmtes Maß überschreitet, d. h. der Proband nicht zur Referenzpopulation gehört, dann werden - wie bei Olshen et al. (1989) - bestimmte pathologische Muster angenommen und eine - wie auch immer geartete - Therapie vorgeschlagen. Entsprechend wichtig ist es diese Intervalle mit der richtigen Breite zu konstruieren, andernfalls gehen etwaige Effekte im Rauschen unter (zu weit) oder es werden Effekte angenommen, die so gar nicht auftreten (zu eng).


Die Bland & Altman Methode setzt normalverteilte, homoskedastische und unabhängige Differenzen voraus. Diese Annahmen sind allerdings beim Vergleich verschiedener Messmethoden häufig verletzt. Die Verteilung der Differenzen zwischen zwei Systemen wird z. B. erheblich verzerrt, wenn Sensorwerte wegen einer Begrenzung des Messbereichs oder der Auflösung abgeschnitten werden, oder wegen (nichtlinearem) Drift. Die Unabhängigkeitsannahme wird dann verletzt, wenn messwiederholte Daten vorliegen. Meswiederholte Werte sind sich i. d. R. ähnlicher (d. h. sie streuen weniger) als die Kurven verschiedener Probanden. Entsprechend besteht die Gefahr, die Streuung der Differenzen zwischen zwei Messmethoden zu unterschätzen. Um dem entgegenzuwirken, verwenden Roislien nur jeweils eine Kurve je Proband, was wiederum zu Lasten einer erheblichen Unsicherheit bezüglich der Streuung der berechneten LoA erkauft wird.

Stichprobengröße: Es kann natürlich gut sein, dass die punnktweisen Verfahren bei höheren Stichprobenumfängen besser performen.

Die Berechnung der LoA ist mit bestimmten (parametrischen) Modellvoraussetzungen verbunden, dass ist aber am Ende eigentlich egal, weil: Was mache ich denn wenn die verletzt sind?


Wir können natürlich nicht mit vier Datensätzen die gesamte Bandbreite abdecken, obwohl damit schon sehr viele Anwendungsfälle abgedeckt werden. Weiterhin ist der Anwendungsbereich auf eine spezielle Art von Kurven (glatte Kurve) beschränkt. Kurven mit vergleichbaren Eigenschaften werden von vielen biomechanischen Messsystemen erzeugt:  Bestimmte Bodenreaktionskräfte (horizontal), tiefpassgefilterte Signale, COP Verläufe etc.. Es gibt aber auch Kurven die ganz andere Charkteristiken wie z. B. Sprünge/Unstetigkeiten im Verlauf (vertikale Bodenreaktionskurven), hohe Rauschanteile (z. B. EMG, ungefilterte Beschleunigungssignale), nichtstationäres Verhalten (z. B. Drift bei intergrierten Gyrosignalen) aufweisen. Es ist nicht klar inwiefern die untersuchten Methoden auch bei diesen Signalen brauchbare Ergebnisse liefern. Gerade bei Signalen mit sprunghaften Änderungen ist denkbar dass punktweise Intervalle zu plausibleren Ergebnissen führen können.
<!-- Lenhoff geht z. B. nicht für nichtstionäre Signale! -->


KONFIDENZINTERVALLE VS. PRÄDIKTIONSINTERVALLE
<!-- Prädiktionsbänder sind kontinuierliche Intervalle, in denen eine zukünftige Beobachtung einer Zufallsvariablen (Messkurve) mit einem gegebenen Konfidenzniveau enthalten ist. Anhand dieser Prädiktionsbänder werden Entscheidungen über die Form und den Effekt von Behandlungen für einzelne Probanden getroffen. Zu enge Prädiktionsbänder implizieren im beschriebenen Anwendungsfall, dass der Gang eines Probanden ein von der Norm abweichendes Muster aufweist, dass behandelt werden muss.  -->
Der hier beschriebene Anwendungsfall (Prädiktionsbänder) deckt natürlich nur ein gewisses Spektrum relevanter Fragestellungen ab. In vielen weit verbreiteten Studiendesigns, z. B. Interventionsstudien, ist mit den breiten Prädiktionsbändern oder den noch breiteren Toleranzbändern nicht viel zu holen. Mit den im Paper kontruierten Bändern würde nahezu jeder Effekt im Messfehlintervall untergehen. In solchen Fällen Studien sind aber ohnehin eher Mittelwerte von Interesse, die in Signifikanztests auf Unterschiede untersucht werden. In diesem Fall sind die schmaleren Konfidenzintervalle eher geeignet um die Abweichung/Übereinstimmung zwischen den gemessenen Mittelwertkurven zweier Messsysteme zu beschreiben.
<!-- Für Details zu Unterschieden in den coverage properties von LoA und herkömmlichen Prädiktionsintervallen sei an dieser Stelle auf Francq et al. (2020) verwiesen. -->

<!-- LENHOFF -->
<!-- In some research studies it is important to determine confidence bands for the mean curve of a given population. For example, a researcher might want to characterize the effect upon the mean external varus moment of a group of subjects treated with a given type of knee brace. In this example, the researcher would wish to determine a confidence band for the mean difference in the external varus moment for subjects while wearing the brace and the external varus moment for the same subjects while not wearing the brace. If the confidence -->
<!-- band about the difference of the braced and un-braced curves of each subject contains the horizontal line at value zero, then one could state that there was no significant difference between the two conditions. This application is illustrated in Fig. 1. -->


https://statmodeling.stat.columbia.edu/2010/12/05/what_do_practit/
The key assumptions of a regression model are validity and additivity. Except when you’re focused on predictions, don’t spend one minute worrying about distributional issues such as normality or equal variance of the errors.


Wir empfehlen grundsätzlich die Daten zu plotten. Am Ende ist jeder Datensatz bzw. jede Fragestellung unterschiedlich und ein pauschaler coverage value wird der Qualität des Messgeräts (in Bezug auf die jeweilige Fragestellung möglicherweise nicht gerecht).

Die Erkenntnisse der vorliegenden Studie können nicht 1:1 auf andere Arten von Daten (z. B. Bodenreaktionskraftkurven, EMG Signale) übertragen, sondern gelten primär für glatte Kurven.

SPM
Pataky: A methodology called Statistical Parametric Mapping (SPM) (Friston et al., 2007) can partially offset these limitations by providing a framework for the continuous statistical analysis of smooth bounded nD fields.

Trotz der theoretisch und praktisch demonstrierten Überlegenheit funktionaler Verfahren konnten sich deren Einsatz im Kontext der Validierung von Messinstrumenten noch nicht recht durchsetzen. Wir spekulieren, dass dies in direktem Zusammenhang mit der Komplexität der Verfahren steht, die eine hohe Hürde für viele Praktiker mit weniger ausgeprägten Statistik- und Programmierkenntnissen darstellt. Um die Verbreitung funktionaler Methoden zu katalysieren stellen wir daher die bei der Erstellung des Papers implementierten Methoden als R Code frei zur Verfügung (GPL).

Angesichts der überragenden Bedeutung der Kenntniss des Messfehlers ist es erstaunlich wie wenig sich viele Studien mit der Frage nach der Größe des Messfehlers beschäftigen. Gut demonstrieren lässt sich das am Beispiel von IMU's ...


Als Ansatz für die Konstruktion besserer Bänder:
Nichtparametrischer Ansatz mit Perzentilen (asymmetrische Bänder)




Wir glauben dass die geringe Verbreitung kontinuierlicher Methoden trotz erwiesenermaßen gut funktionierender Methoden in der Praxis an der programmiertechnischen Umsetzung scheitert. Wir hoffen mit diesem Paper und dem Code im Anhang einen Beitrag dazu zu leisten, dass mehr Forscher diese Methoden adaptieren und veralteten/ungeeigneten Methoden (Korrelationskoeffizienten etc.) den Rücken kehren.


<!-- Es gibt auch immer mehr readily available (und kostenlose) Lösungen, siehe https://mjskay.github.io/ggdist/articles/lineribbon.html -->

<!-- Limitations of curvewise intervals -->
<!-- https://mjskay.github.io/ggdist/articles/lineribbon.html -->
<!-- One challenge with curvewise intervals is that they can tend to be very conservative, especially at moderate-to-large intervals widths. -->
<!-- Notice how noisy the curvewise intervals are. In addition, because a number of curves tend to start low and end high (or vice versa), above 50%, the bands rapidly expand to cover almost all of the curves in the sample, regardless of coverage level. -->
<!-- In general I have found that there is no one method that consistently works well on all datasets. No matter the method, intervals often become problematic above 50%, hence the default .width for curve_interval() is 0.5 (unlike the default for point_interval(), which is 0.95). In any case, caution when using these intervals is advised. -->

<!-- Welcher coverage Strategie ist besser (Entire curve (all-or-nothing) vs. percent-of-curve)? -->
<!-- Denkansatz aus Juul et al. (2020) -->
<!-- At the same time, however, it is clear that there is still important research to be done. We have suggested different ways of ranking centrality of ensemble curves. Each rank- -->
<!-- ing has its merits: For example, the all-or-nothing ranking penalizes curves which are shaped differently than other ensemble curves and a weighted ranking can reward curves that are central in the very near future. A thorough investigation of these merits and trade-offs is needed. Until this has been investigated, we encourage researchers to be creative and mindful about the problems that each statistical method could have. And to communicate this uncertainty openly to decision makers. -->

<!-- Für die hier untersuchten biomechanischen Signale nicht so relevant, aber an sich ein sehr interessantes Feature ist das hier: -->
<!-- Leicht abgewandelt nach Juul et al. (2020): -->
<!-- In addition to the ranking methods (for finding quantiles/percentiles) mentioned above, one can rank the curves according to some feature of interest. In Fig. 2E we show the curve box plots obtained when we rank curves according to their projected maximum values of newly hospitalized cases in a single day; in other words, the median projected peak value received -->
<!-- the highest centrality. -->

<!-- Interessant beim Juul Paper ist auch der Umgang mit ("abgeschnittenen") Extremwerten: -->
<!-- Here we have argued that computing confidence intervals using fixed-time descriptive systematically suppresses trajectory extremes. This is natural. -->
<!-- Fixed-time descriptive statistics are designed to show the least extreme predictions on a given date, not to take entire curves into account. -->

<!-- <!-- Es gibt eine Reihe von Ansätzen aus anderen Bereichen (z. B. Covid Prädiktion), bei denen sog. Function oder Curve Boxplots eingesetzt werden. -->
<!-- <!-- https://mjskay.github.io/ggdist/reference/curve_interval.html -->
<!-- <!-- Hier referenzierte Paper u. a.  -->
<!-- <!-- - Juul Jonas, Kaare Græsbøll, Lasse Engbo Christiansen, and Sune Lehmann. (2020). "Fixed-time descriptive statistics underestimate extremes of epidemic curve ensembles". arXiv e-print. arXiv:2007.05035 -->
<!-- <!-- - Mirzargar, Mahsa, Ross T Whitaker, and Robert M Kirby. (2014). "Curve Boxplot: Generalization of Boxplot for Ensembles of Curves". IEEE Transactions on Visualization and Computer Graphics. 20(12): 2654-2663. doi: 10.1109/TVCG.2014.2346455 -->

<!-- <!-- See Mirzargar et al. (2014) or Juul et al. (2020) for an accessible introduction to data depth and curve boxplots / functional boxplots. -->

# Conclusion

<!-- Aus Juul et al. (2020) -->
<!-- In summary, when making forecasts of epidemic trajectories, it is important to represent the resulting curve ensembles in a way that captures the quantities of interest -->
<!-- in an intuitive way. -->

