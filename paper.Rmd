---
title: Comparison of continuous prediction intervals for the validation of biomechanical curve data
author:
- name: Daniel Koska
  email: daniel.koska@hsw.tu-chemnitz.de
  affiliation: Chemnitz University of Technology, Research Methodology and Data Analysis
    in Biomechanics
  footnote: Corresponding Author
- name: Doris Oriwol
  email: doris.oriwol@partner.kit.edu
  affiliation: Karlsruhe Institute of Technology
- name: Christian Maiwald
  email: christian.maiwald@hsw.tu-chemnitz.de
  affiliation: Chemnitz University of Technology, Research Methodology and Data Analysis
    in Biomechanics
date: "`r format(Sys.time(), '%d %B, %Y')`"
journal: An awesome journal
abstract: |
  Paper als short communication / technical note?

header-includes:
  - \usepackage{amsmath}
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
  pdf_document:
    toc: yes
---

### TODO
- Rolle von Messwiederholungen in der Fragestellung definieren!?
- Erklarende Abbildung Methodenkapitel uncertainty estimation (aehnlich Diss Doris)
- Formelnummerierung
<!-- - Exemplarische Paper für die jeweiligen simulierten Datensätze raussuchen -->
- Begriff concurrent validity reinbringen

<!-- ### TODO read (again) -->
<!-- - White Basics of Estimating Measurement Uncertainty -->
<!-- - Francq B, Govaerts B. How to regress and predict in a Bland-Altman plot? Review and contribution based on tolerance intervals and -->
<!-- correlated-errors-in-variables models. Statist Med. 2016;35:2328-2358. -->
<!-- - Francq Confidence, prediction, and tolerance in linear mixed models -->
<!-- - Vock (2016) -->
<!-- - Parker et al. (2021) https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-01022-x -->
<!-- - Robinson, Vanrenterghem, Pataky (2021) Sample size estimation for biomechanical waveforms: Current practice, recommendations and a comparison to discrete power analysis -->
<!-- - Olshen et al. (1989) Gait analysis and the bootstrap -->
<!-- - Curvewise point and interval summaries for tidy data frames of draws from distributions https://mjskay.github.io/ggdist/reference/curve_interval.html -->
<!-- - Horvath, Kokoszka & Reeder (2013) Estimation of the mean of functional time series and a two-sample problem -->
<!-- - Generell die Kooperationspaper von Hörmann und Kokoszka zu FDA Statistik,insbesondere 'Inference for Functional Data with Applications' (2012) -->
<!-- - Ratkowsky 1990 Handbook of nonlinear regression models -->
<!-- - Meeker et al. Statistical intervals -->
<!-- - Juul et al. (2020) lesen -->


```{r echo = FALSE, warning = FALSE, message = FALSE}
library(ggplot2)

dir.script <- "~/floa/R"
dir.data <- "~/floa/R/examples"

setwd(dir.script)

source("example_data.R")
source("pick_subwise_curves.R")
source("draw_clusters.R")
source("floa_rcb.R")
source("floa_boot.R")
source("floa_point.R")
source("floa_roislien.R")
source("plot_loa.R")
source("get_coverage.R")
source("get_coverage_fraction.R")
source("get_coverage_singlecurve.R")
source("get_coverage_singlecurve_fraction.R")
source("crossval_coverage.R")
source("crossval_coverage_fraction.R")
source("singlecurve_coverage.R")
source("singlecurve_coverage_fraction.R")
source("plot_cov_ver.R")
source("estimate_uncertainty_loa.R")
```

# Introduction
Die Biomechanik ist eine empirische Wissenschaft, d. h. der Erkenntnisgewinn basiert auf der Qualität experimenteller Daten und hängt damit direkt von der Güte der eingesetzten Messverfahren ab. Die Beurteilung der Validität des Messverfahrens erfolgt üblicherweise über den Vergleich eines zu validierenden Messsystems mit einem bereits etablierten. Dabei werden Bewegungen mit beiden Messsystemen simultan aufgezeichnet und die Messwerte verglichen, wobei ein möglichst hoher Übereinstimmungsgrad vorliegen sollte. 

Die statistische Aufbereitung der gemessenen Abweichungen ist bereits bei 0D Punktdaten (z. B. body mass) nicht trivial (Bland & Altman, 1983) und wird zusätzlich erschwert, wenn höherdimensionale Daten vorliegen, z. B. in Form von 1D Kurvendaten (z. B. Gelenkwinkel, Bodenreaktionskurven, COP Trajektorien, EMG-Signale), 2D Matrizen (z. B. Druckverteilungsdaten), oder 3D Arrays (z. B. bone strain fields). Höherdimensionale Daten weisen gegenüber 0D Daten zwei wesentliche Unterschiede auf: 1. Der Messfehler variiert über der Zeit und 2. benachbarte Samplingpunkte sind nicht unabhängig, sondern lokal korreliert (Deluzio & Astephen, 2007; Pataky, 2010).

In den allermeisten Validierungsstudien werden diese Charakteristika allerdings durch Diskretisierung (Reduzierung auf Einzelpunkte oder skalare Features wie z. B. local extrema, rates of change, or ranges of motion) ignoriert um die statistische Auswertung und Interpretation der Daten zu vereinfachen. Daraus ergeben sich eine Reihe von Problemen hinsichtlich der Bewertung des Messfehlers: (i) non-stationary error processes are not considered (ii) the validity of statements derived from discrete variables is limited by domain alignment (i. e. phase shift) and the risk of examining points that have little relevance for the system under investigation (Donoghue et al., 2008; Pataky et al., 2008; Richter et al., 2014; Park et al., 2017) (iii) wenn inferenzstatistische Verfahren wie Konfidenz- oder Prädiktionsintervalle simultan auf mehrere Samplingpunkte angewandt werden um kontinuierliche Fehlerbänder zu konstruieren, ist zu erwarten, dass die zufällige Fehlerkomponente unterschätzt wird weil die (nonzero) Kovarianz benachbarter Samplingpunkte nicht berücksichtigt wird (Lenhoff et al., 1999; Olea & Plagborg-Moeller, 2018;). Die üblicherweise eingesetzten Korrekturverfahren zur Anpassung des alpha levels (Hochberg & , 1987) führen aufgrund der hohen Anzahl an Samplingpunkten zu extrem konservativen Schätzungen des zufälligen Fehlers.

Lenhoff et al. (1999) haben das Problem punktweise konstruierter Bänder am Beispiel von 1D Gelenkwinkelverläufen (Kurven) demonstriert. Dazu verglichen sie punktweise berechnete Prädiktionsbänder gegenüber einer funktionalen Methode bei der Kurvendaten zunächst mithilfe von Fourierfunktionen approximiert werden und aus den so gebildeten funktionalen Kurven durch Bootstrapping Prädiktionsbänder gebildet werden (Sutherland, Olshen, Biden & Wyatt (1988, 1989)). They found that these prediction bands provided appropriate coverage for continuous curve gait data (86% coverage at 90% nominal coverage level) while pointwise Gaussian bands were shown to provide inadequate coverage (54%).

Røislien et al. (2012) haben einen Ansatz präsentiert, mit dem die von Bland & Altman (1983) vorgeschlagene Methode zur Konstruktion von Übereinstimmungsintervallen, sog. Limits of Agreement (LoA: 95% der Differenzen zwischen zwei Messsystemen sind im Intervall mittlere Differenz $\pm$ 1.96 Standardabweichungen der Differenzen enthalten), für Kurvendaten erweitert wird. LoA sind das am weitesten verbreitete Verfahren in Methodenvergleichen (Ludbrook, 2010) und stellen per Definfition Prädiktionsintervalle dar (obwohl das tatsächliche Prädiktionslevel der LoA stets niedriger ist als das nominale Niveau und für kleine Stichproben kollabiert (Francq, 2020)). 

Das primäre Anliegen des vorliegenden Papers ist die Gegenüberstellung punktweiser gegen funktionale Methoden zur Konstruktion kontinuierlicher Fehlerintervalle für 1D Kurvendaten im Rahmen einer Messsystemvalidierung. Demonstriert werden soll das mithilfe simulierter und realer Datensätze exemplarisch für Prädiktionsbändern die mit drei verschiedenen Methoden konstruiert werden: (1) punktweise Bland and Altman LoA (2) LoA nach Roislien et al. (2012) und (3) gebootstrappte funktionale Prädiktionsbänder (Sutherland, Olshen, Biden & Wyatt (1988, 1989), Lenhoff et al. (1999)). Zudem soll praktische Hinweise zur Konstruktion und zum Einsatz unterschiedlicher Fehlerbänder für verschiedene Anwendungsszenarien (Untersuchungsdesigns) abgeleitet werden.

# Methods

Um die Vergleichbarkeit der verschiedenen Methoden zu gewährleisten, erfolgt die Konstruktion der Fehlerintervalle in allen drei Methoden anhand von Differenzen(kurven).

### Data sets

Für den Vergleich der Methoden wurden vier Datensätze (drei simulierte und ein realer) verwendet. Jeder Datensatz enthält jeweils $N = 220$ Kurven der Länge $T = 101$ Datenpunkte aus $M = 2$ Messsystemen. Das entspricht in jedem Datensatz $D = 110$ Differenzkurven (Differenzen zwischen den Messsystemen):

\begin{equation}
\tag{1}
\sum D_{ij} = \sum_{i=1}^{I} \sum_{j=1}^{J} Y_{ij} - X_{ij} = 110
\label{eq:mean}
\end{equation}

X und Y sind (I x J) Messwertmatrizen mit je $I = 11$ Probanden und $J = 10$ wiederholten Kurven pro Proband. Alle simulierten Datensätze wurden als glatte Kurven, ähnlich Gelenkwinkelverläufen, mit dem gleichen Grundmodell generiert. Dazu wurden für jedes Messsystem zwei Sinusfunktionen überlagert:

$$
X_{ij} = bias + A_{1}sin(B_{1}t) + A_{2}sin(B_{2}t)^{c + 3}, \\Y_{ij}(t) = bias + A_{1}sin(B_{1}t) + A_{3}sin(B_{2}t)^{c + 3}
$$

$A_{1,2,3}$ und $B_{1,2}$ sind Zufallsvariablen mit variierenden Verteilungseigenschaften (normal, uniform, Weibull), über deren Parameter Abweichungen zwischen Probanden (between subject variation), Schritten (within subject variation) und Messystemen abgebildet sind. $c$ ist eine Konstante ($c = 2$). Zudem wurden - je nach Datensatz - Offsets als normalverteilte Zufallsvariablen mit probandenweise variierenden Mittelwerten ($\mu_{i}$ modelliert:

$$
bias \sim N(\mu_{i}, \sigma=0.05)
$$
Auf eine Modellierung systematischer Offsets zwischen beiden Messsystemen wurde verzichtet da sich diese lediglich auf die Breite der Intervalle auswirken, nicht aber auf die qualitativen Verläufe der Intervallgrenzen. Um die Reproduzierbarkeit der Datensätze zu gewährleisten wurden alle Zufallsvariablen mit einem random seed initialisiert. Der Code für die Generierung der Kurven kann im Anhang im Detail nachvollzogen werden.

```{r echo = FALSE, warning = FALSE, message = FALSE}
data <- example_data(dat = "smooth_realistic", dir.data)
data.single.mc <- subset(data, device == "MC")
data.single.imu <- subset(data, device == "IMU")

PLOT.1 <- ggplot(data = data.single.mc, aes(x = frame, y = value, group = strideID)) +
  geom_line() +
  scale_color_grey(start = 0.6, end = 0.9) +
  geom_line(data = data.single.imu, aes(x = frame, y = value, group = strideID, colour = as.factor(subjectID)), alpha = 0.3) +
  labs(x = "Time-normalized signal [%]", y = "Angle [°]") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "none")


data <- example_data(dat = "non_gaussian", dir.data)
data.single.mc <- subset(data, device == "MC")
data.single.imu <- subset(data, device == "IMU")

PLOT.2 <- ggplot(data = data.single.mc, aes(x = frame, y = value, group = strideID)) +
  geom_line() +
  scale_color_grey(start = 0.6, end = 0.9) +
  geom_line(data = data.single.imu, aes(x = frame, y = value, group = strideID, colour = as.factor(subjectID)), alpha = 0.3) +
  labs(x = "Time-normalized signal [%]", y = "Angle [°]") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "none")


data <- example_data(dat = "shift", dir.data)
data.single.mc <- subset(data, device == "MC")
data.single.imu <- subset(data, device == "IMU")

PLOT.3 <- ggplot(data = data.single.mc, aes(x = frame, y = value, group = strideID)) +
  geom_line() +
  scale_color_grey(start = 0.6, end = 0.9) +
  geom_line(data = data.single.imu, aes(x = frame, y = value, group = strideID, colour = as.factor(subjectID)), alpha = 0.3) +
  labs(x = "Time-normalized signal [%]", y = "Angle [°]") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "none")


data <- example_data(dat = "imu_mc", dir.data)
data.single.mc <- subset(data, device == "MC")
data.single.imu <- subset(data, device == "IMU")

PLOT.4 <- ggplot(data = data.single.mc, aes(x = frame, y = value, group = strideID)) +
  geom_line() +
  scale_color_grey(start = 0.6, end = 0.9) +
  geom_line(data = data.single.imu, aes(x = frame, y = value, group = strideID, colour = as.factor(subjectID)), alpha = 0.3) +
  labs(x = "Time-normalized signal [%]", y = "Angle [°]") +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.y = element_text(size = 14),
        legend.position = "none")
```


```{r echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Figure 1: Kurvenverläufe in den jeweiligen Datensätzen (A - D). Schwarze Kurven im Hintergrund sind die Werte des Referenzsystems."}
PLOT <- ggpubr::ggarrange(PLOT.1, PLOT.2, PLOT.3, PLOT.4,
                          labels = c("A", "B", "C", "D"),
                          ncol = 2,
                          nrow = 2)
PLOT

ggsave("~/Nextcloud/project-fab-forschung/Publikationen/FLOA/tex/Grafiken/original_curves.png", device = "png", dpi = 300)
```

Fig. 1 stellt die originalen Kurven beider Messsysteme in den vier verwendeten Datensätzen (A - D) dar:

* Datensatz A : Simulated curves with Gaussian error model ($\epsilon_{i} \sim N (0, \sigma_{i}^2)$).

Die Daten repräsentieren den Fall dass beide Messysteme qualitativ ähnliche Messkurven erzeugen.

* Datensatz B : Simulated curves with non-Gaussian errors and heteroskedasticity

Einer der Skalierungsparameter des zweiten Messsystems ($A_{3}$) ist als normalverteilte Zufallsvariable mit Weibull-verteiltem Mittelwert modelliert ($\epsilon_{i} \sim N(\mu \sim Wei(\gamma = 1.5,\alpha  = 1), \sigma_{i})$). Derartige Datensätze liegen dann vor, wenn mindestens eines der Messsysteme Kurven produziert, die in bestimmten Kurvenabschnitten deutlich vom wahren Wert abweichen (hier: Messsystem 2, grau). In diesem Fall sind elementare Voraussetzungen für den Einsatz parametrischer Modelle (wie z. B. Bland and Altman LoA) erheblich verletzt.

* Datensatz C : Simulated curves curves with Gaussian error model and phase shift in x-axis direction.

Die Kurven wurden mit dem selben Modell wie in (A) erstellt, aber die Kurven von Messsystem 2 (grau) sind auf der x-Achse verschoben. Auch hier sind Modellvoraussetzungen erheblich verletzt, die Differenzen weisen aber eine andere Verteilung auf als in Modell (B). In der Praxis treten vergleichbare Kurvenverläufe auf, wenn die Messung eines Systems in ihrem zeitlichen Verlauf in irgendeiner Weise systematisch beeinflusst wird, z. B. durch Filterartefakte.

* Datensatz D : Real-world hip joint angle curves

Data from healthy subjects walking at 6 km/h on a treadmill without gradient recorded simultaneously recorded using an optical motion capture system (MC) and an inertial measurement unit (IMU). Die Kurven unterscheiden sich qualitativ und quantitativ von den übrigen Datensätzen. Die Streuung innerhalb und zwischen den Probanden ist stärker ausgeprägt und weniger homogen als in den simulierten Datensätzen.

Insgesamt wurde die Anzahl der Messkurven im Datensatz bewusst klein gehalten um dem typischen Stichprobenumfang vieler Validierungsstudien zu entsprechen. Die Kurven korrespondieren nicht mit realen Signalen und wurden teilweise bewusst überspitzt konstruiert um den Einfluss ausgewählter Fehlercharakteristika (nicht Gauss'sche Fehler, Heteroskedastizität, Phasenshift) auf das Verhalten der Bänder hervorzuheben.

<!-- Der Code zum Erstellen der Kurven findet sich im Anhang und auf Github als R Code und txt Dateien. -->

### Calculation methods

Um die Vergleichbarkeit der Ergebnisse zu gewährleisten, wurden in allen drei untersuchten Verfahren Differenzkurven als Berechnungsgrundlage der Prädiktionsbänder verwendet. Analysiert wurden:

* 1. Pointwise continuous LoA according to Bland & Altman (1999, 2007) (POINT)

Über alle $D$ Kurven wurden separat für alle $T = 101$ Punkte klassiche (diskrete) LoA berechnet. Bei erfüllten Modellvoraussetzungen (unabhängige Kurven, normalverteilte Differenzen, Homoskedastizität), kann erwartet werden, dass ungefähr 95% der Differenzen im Intervall mean difference $\pm$ 1.96standard deviation of the differences liegen. 1.96 entspricht dem 0.975 Quantil der Standardnormalverteilung (Bland & Altman, 1986). In der vorliegenden Arbeit wird ein komplexeres Modell für wiederholte Messungen verwendet, in dem sich der wahre Wert über jedes Differenzpaar ändert (Bland & Altman, 1999). Das Modell beschreibt die Differenz zwischen zwei Messsystemen als Summe der mittleren Differenz und zweier Varianzkomponenten (between ($\sigma^2_{db}$), within ($\sigma^2_{dw}$)):
<!-- Auch wenn hier jeweils die gleiche Anzahl Kurven für jedes Messsystem vorliegt, erlaubt die verwendete Formel die Übertragung auf den unbalancierten Fall. -->

$$
D_{ij} = \overline{d} + \sqrt{\sigma^2_{db} + \sigma^2_{dw}}
$$
Die beiden Varianzkomponenten werden mithilfe einer einfaktoriellen Varianzanalyse bestimmt. \sigma^2_{dw} kann als residual mean square ($MS_{w}$) direkt aus dem ANOVA table abgelesen werden. \sigma^2_{db} berechnet sich aus der Differenz aus between-subject mean squares und $MS_{w}$, geteilt durch einen Term, der die Anzahl der Probanden und Kurven berücksichtigt. Wenn für alle Probanden die gleiche Anzahl an Datenpunkten vorliegt (wie im vorliegenden Fall), reduziert sich dieser Term auf die Anzahl der Datenpunkte (Kurven) pro Proband ($j = 10$):

$$
\sigma^2_{db} = \frac{(MS_{b} - MS_{w})}{j}
$$
Für weiterführende Informationen zur Berechnung (z. B. bei ungleicher Anzahl Observationen pro Proband) siehe Bland & Altman (1999, 2007) sowie die zugehörige Implementierung als R Code im Anhang.

* 2. Functional limits of agreement (FLoA) according to Roislien et al. (2012) (ROISLIEN)

Die Methode von Røislien et al. (2012) wurde als Erweiterung der diskreten LoA für Kurvendaten vorgestellt. Dazu werden die Differenzkurven zunächst mithilfe von Fourier Funktionen angenähert. Die Berechnung der LoA erfolgt im Anschluss allerdings - genau wie in POINT - separat für jeden Punkt der Kurve. De facto bietet die Verwendung funktionaler Kurven mit diesem Ansatz keinen Vorteil gegenüber dem punktweisen Vorgehen, weshalb im Rahmen dieses Papers auf die Repräsentation der Kurven als Funktionen verzichtet wurde. Gegenüber dem Vorgehen in POINT werden zudem keine wiederholten Kurven verwendet, sondern nur je eine Kurve pro Proband um die Modellvoraussetzung der Unabhängigkeit der Kurven nicht zu verletzen. Die Berechnung der LoA für diesen reduzierten Datensatz ($j = i$ Kurven) erfolgt mithilfe des minimalen Bland & Altman Modells ($\overline{d} \pm 1.96SD$).

Das ROISLIEN Verfahren wurde in die Analyse aufgenommen um den Einfluss fehlender Meswiederholunge als Repräsentation intersubjektiver Varianz zu demonstrieren.

* 3. Boostrapped functional prediction bands according Sutherland et al. (1988), Olshen et al. (1989) and Lenhoff et al. (1999) (BOOT)

Die Methode ist die einzige der vorgestellten Methoden, die vollständig funktional arbeitet, d. h. die Konstruktion der Prädiktionsbänder findet nicht punktweise, sondern auf Grundlage ganzer Kurven statt. Damit bleibt die lokale Abhängigkeit der Kurvenpunkte erhalten. Die Prädiktionsbänder werden mithilfe eines iterativ ermittelten Korrekturfaktors ($C_{p}$) bestimmt, der mittels Bootstrapping bestimmt wird. Bootstrapping ist ein nicht-parametrisches Verfahren und kommt daher ohne Annahmen zur Verteilung der Differenzen aus. Die folgende Beschreibung der Methode orientiert sich an der Beschreibung in Lenhoff et al. (1999).

Im ersten Schritt werden alle $D$ Differenzkurven mithilfe von Fourier-Reihen als Funktionen approximiert:

$$
f_{d}(t) = \mu_{d} + \sum_{k=1}^K(\alpha_{dk}cos(\frac{2\pi kt}{T}) + \beta_{dk} sin(\frac{2\pi kt}{T}))
$$

wobei $d = 1,...,D$. Die Methode setzt voraus dass der Start- und Endpunkt der untersuchten Kurven auf dem gleichen Niveau liegen sollten, was bei perodischen Kurven wie Gelenkwinkeln oder Bodenreaktionsverläufen üblicherweise erfüllt ist. Die Anzahl der Basisfunktionen $K$ ist so zu wählen, dass die Kurven bestmöglich angenähert werden und keine ungewollten Glättungseffekte entstehen. In der vorliegenden Arbeit wurde großzügig $K = 50$ gewählt. Die Koeffizienten ($\mu_{n}, \alpha_{n1}, \beta_{n1}, ..., \alpha_{nK}, \beta_{nK}$) werden durch die Methode der kleinsten Quadrate bestimmt und ermöglichen die Schätzung der Originalkurven durch $\hat{f}_{d}(t)$ (Einzelkurven) und $\hat{f}(t)$ (mittlere Kurve).

Aus der zugehörigen Koeffizientenmatrix werden durch Bootstrapping $B = 400$ mal die Koeffizienten von $D$ Kurven mit Zurücklegen gezogen, für die jeweils die mittlere Kurve $\hat{f^b}(t)$ und Variabilität $\hat{\sigma}_{\hat{f}^b(t)}$ bestimmt werden. Im Mittel über alle Bootstrapiterationen lässt sich daraus der Anteil der Kurven bestimmen, deren maximale standardisierte Abweichung vom Bootstrap-Mittel kleiner gleich $C_{p}$ ist.

$$
\frac{1}{B} \sum_{b=1}^B [\frac{1}{D} \sum_{d=1}^D I(\max_{t} (\frac{|\hat{f}_{d}(t) - \hat{f^b}(t)|}{\hat{\sigma}_{f(t)}} \le C_{p})]
$$
wobei $I(E)$ eine logische Matrix darstellt, die Werte von 0 oder 1 annimmt, wenn die zugehörige Ungleichung zutrifft. $C_{p}$ ist ein zu bestimmendes Quantil das durch Bootstrapping iterativ ($B$ mal) so optimiert wird, dass es der gewünschten coverage probability des Prädiktionsbandes $P = 1- \alpha$ (hier: $\alpha=0.05$) entspricht. $B$ sollte dabei möglichst groß gewählt werden (hier: $B = 400$). Damit berechnet sich das Prädiktionsband als:

$$
\hat{f}(t) \pm C_{p} \hat{\sigma}_{\hat{f}(t)}
$$



```{r echo = FALSE, warning = FALSE, message = FALSE}
# Wrapper function for example data sets. Function arguments:
#
# (* Empirical validation data: "imu_mc")
# * Smooth, wave data (normal error, constant variance, no trend): "smooth"
# * Smooth wave data with nonlinear trend (constant variance): "smooth_trend"
# * Data with non-gaussian (Weibull distributed) error (no trend): "non_gaussian"
# * Data with shock peaks (no bias, no trend): "shock"
data <- example_data(dat = "smooth", dir.data)

# Mean and SD are calculated across all strides (and subjects).
# No bootstrap or other resampling strategies are applied.
floa.point <- floa_point(data)
```


### Leave-one out cross validation

Für die Bewertung der coverage Performance wurden die untersuchten Methoden im leave-one-out Verfahren kreuzvalidiert. Dazu wird der Datensatz in einen Trainings- und Testdatensatz gesplittet, wobei der Testdatensatz genau einer Differenzkurve entspricht. Dieser Vorgang wird $D$ mal für alle Differenzkurven des Datensatzes wiederholt und folgende coverage Parameter für die Testkurven berechnet:

1. Prozentualer Anteil (proportion) der im Prädiktionsband enthaltenen Punkte einer Kurve

Median, Modalwert und Range (Minimum, Maximum) von $x$ über alle Kurven, wobei $x$ der prozentuale Anteil der Punkte je untersuchter Kurve ist, die innerhalb der $upper$ und $lower$ limits des Prädiktionsbandes liegen:

$$
\{x \in D \mid  \frac{1}{T} \sum_{t=1}^T (upper \leq  x_{t} \leq lower) \cdot 100 \} \\
$$
<!-- $$ -->
<!-- median = -->
<!--   \begin{cases} -->
<!--     x_{\frac{n+1}{2}} & n\text{ odd} \\ -->
<!--     \frac{1}{2}\bigl(x_{\frac{n}{2}}+x_{\frac{n+1}{2}}\bigr) & n\text{ even} -->
<!--   \end{cases} -->
<!-- $$ -->


2. Mittlerer prozentualer Anteil der vollständig im Prädiktionsband enthaltenen Kurven (all-or-nothing Prinzip)

$$
\frac{1}{D}  \sum_{d=1}^D H(x_{d}) \cdot 100
$$
wobei $H$ eine Heaviside Funktion ist

$$
H(x) =
  \begin{cases}
    0 : x_{d} < 1 \\
    1 : x_{d} = 1
  \end{cases}
$$

### Uncertainty estimation
Die Grenzen der Prädiktionsintervalle unterliegen einem stochastischen Prozess und variieren in Abhängigkeit vom Samplingprozess in den jeweiligen Verfahren (POINT, ROISLIEN, BOOT). Um diese Unsicherheit der Intervallgrenzen zu quantifizieren, wurde der Abstand zwischen einer oberen und unteren Unsicherheitsgrenze (Erläuterung und Berechnungsdetails im Folgenden) als kumulierter Flächeninhalt (Cumulated Uncertainty Measure) durch punktweises Aufsummieren der Differenzen berechnet (Oriwol, 2012):

$$
CUM = \sum_{t=1}^T|upper_{t} - lower_{t}|
$$

Im vorgestellten POINT Verfahren nach Bland & Altman ergibt sich keine Streuung der Prädiktionsintervallgrenzen, da jeweils alle Kurven in die Berechnung der LoA eingehen. Bland & Altman (1986) schlagen jedoch 95% Konfidenzintervalle (CI) als Erweiterung des ursprünglichen Ansatzes vor, um die - insbesondere bei kleineren Stichproben auftretenden - Schwankungen zu berücksichtigen,

$$
LoA \pm 95\% CI: (\overline{d} \pm z_{0.975}SD) \pm t_{0.975, n-1}SD\sqrt{\frac{1}{D} + \frac{z^2_{0.975}}{2(D-1)}}
$$
wobei $t_{0.975, n-1}$ das 97.5% Perzentil der t-Verteilung (n − 1 Freiheitsgrade) ist und $z_{0.975} = 1.96$ das entsprechende Perzentil der Standardnormalverteilung (Bland & Altman, 1999). Die Grenzen der Konfidenzintervalle bilden die oberen und unteren Grenzen des Streuungsintervalls der LoA und können separat für beide LoA berechnet werden. Als Voraussetzung für die Berechnung dieser Konfidenzintervalle gilt, dass die Differenzen annähernd normalverteilt sein müssen. 

Beim ROISLIEN-Verfahren entsteht durch das Ziehen nur jeweils einer zufälligen Kurve pro Proband eine zusätzliche Varianzquelle gegenüber dem POINT Ansatz. Im Rahmen des BOOT-Verfahren variieren die Intervallgrenzen durch wiederholtes Ziehen mit Zurücklegen. Die Ermittlung der Intervallgrenzenstreuung in diesen Verfahren (ROISLIEN, BOOT) erfolgt empirisch. Dazu werden die Intervallgrenzen $B = 400$ mal berechnet und aus der resultierenden Kurvenschar die 2.5% bzw. 97.5% Perzentile als untere bzw. obere Begrenzung für die Streuung der Prädiktionsintervallgrenzen verwendet.

<!-- Nach dem Gesetz der großen Zahlen kann davon ausgegangen werden, dass der Abstand zwischen den Intervallgrenzen mit steigender Iterationszahl abnimmt und sich bei einem bestimmten Wert stabilisiert. -->

<!-- Hier noch eine Grafik der kumulierten Flächen einbringen (siehe Diss Doris und bishere uncertainty plots) -->

# Results
Figure 2 enthält die qualitative Verläufe der Prädiktionsbänder der drei Methoden gegenüber den Differenzkurven. Die Werte für die Abdeckung der Gesamtkurven über alle Datensätze befinden sich in Table 1. Die zugehörigen Parameter für den Anteil der abgedeckten Punkte pro Kurve sind in Table 2 enthalten. Table 3 enthält die Streuung der Prädiktionsbandgrenzen (Cumulated Uncertainty Area).

Die Ergebnisse zeigen, dass die gebootstrappten Prädiktionsintervalle (BOOT) in allen untersuchten Szenarien an die nominale coverage heranreichen. Die BOOT Methode ist dabei robust gegenüber unterschiedlichen Fehlercharakteristika. Die Prädiktionsbänder der punktweisen Verfahren (POINT, ROISLIEN) fallen zum Teil deutlich schmaler aus und unterrepräsentieren den Messfehler in Bezug auf die Abdeckung ganzer Kurven. Bezüglich des Anteils der abgedeckten Punkte pro Kurve erzielen die punktweise konstruierten Bänder sehr gute coverage Werte (Median 100% über alle $D = 110$ Iterationen der leave-one-out Kreuzvalidierung).

Die qualitativen Verläufe der Prädiktionsbänder von POINT und ROISLIEN sind recht ähnlich. Allerdings ist die coverage der ROISLIEN-Bänder im Mittel über alle $D = 110$ Iterationen der leave-one-out Kreuzvalidierung niedriger als die der POINT-Bänder (sowohl bei der Abdeckung ganzer Kurven als auch bei beim Anteil der abgedeckten Kurvenpunkte). Generell weisen die ROISLIEN-Bänder die höchste Unsicherheit bzgl. der Streuung der Intervallgrenzen auf, d. h. die Prädiktionsbänder nach ROISLIEN fallen häufiger zu eng oder zu weit aus. Dabei ist die Unsicherheit der Intervallgrenzen beim ROISLIEN-Verfahren etwas höher als beim POINT-Verfahren und nahezu 3x so hoch wie beim BOOT Verfahren. Die BOOT-Bänder weisen eine deutlich geringere Streuung der Intervallgrenzen auf als die beiden übrigen Methoden.


```{r echo = FALSE, warning = FALSE, message = FALSE}
n.boot <- 5

# Simulated curves with Gaussian error model (A)
data <- example_data(dat = "smooth_realistic", dir.data)

floa.point <- floa_point(data)
floa.roislien <- floa_roislien(data)
floa.boot  <- floa_boot(data,
                        k_reihe = 50,
                        n.boot = n.boot,
                        band = "prediction",
                        cp.begin = 0,
                        alpha = 0.05)

PLOT.1 <- plot_loa(data, floa.point, floa.roislien, floa.boot, ylim = c(-3, 3))


# Simulated curves with non-normal, heteroskedastic differences (B)
data <- example_data(dat = "non_gaussian", dir.data)

floa.point <- floa_point(data)
floa.roislien <- floa_roislien(data)
floa.boot  <- floa_boot(data,
                        k_reihe = 50,
                        n.boot = n.boot,
                        band = "prediction",
                        cp.begin = 0,
                        alpha = 0.05)

PLOT.2 <- plot_loa(data, floa.point, floa.roislien, floa.boot, ylim = c(-8, 8))


# Simulated curves curves with Gaussian error model created and phase shift in x-axis direction (C)
data <- example_data(dat = "shift", dir.data)

floa.point <- floa_point(data)
floa.roislien <- floa_roislien(data)
floa.boot  <- floa_boot(data,
                        k_reihe = 50,
                        n.boot = n.boot,
                        band = "prediction",
                        cp.begin = 0,
                        alpha = 0.05)

PLOT.3 <- plot_loa(data, floa.point, floa.roislien, floa.boot, ylim = c(-5, 5))


# Real-world hip joint angle curves
data <- example_data(dat = "imu_mc", dir.data)

floa.point <- floa_point(data)
floa.roislien <- floa_roislien(data)
floa.boot  <- floa_boot(data,
                        k_reihe = 50,
                        n.boot = n.boot,
                        band = "prediction",
                        cp.begin = 0,
                        alpha = 0.05)

PLOT.4 <- plot_loa(data, floa.point, floa.roislien, floa.boot, ylim = c(-20, 20))
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.cap = "Figure 2: Verlauf der Prädiktionsbänder von POINT (grüne, gepunktete Kurve), ROISLEN (blaue Linie) und BOOT (braune Linie) in den vier Datensätzen (A - Gaussian error model, B - Non-Gaussian errors and heteroskedasticity, C - Gaussian error model and phase shift in x-axis direction, D - Real-world hip joint angle curves). Differenzen zwischen beiden Messsystemen sind als schwarze Kurven Linien im Hintergrund dargestellt."}
PLOT <- ggpubr::ggarrange(PLOT.1, PLOT.2, PLOT.3, PLOT.4,
                          labels = c("A", "B", "C", "D"),
                          ncol = 2,
                          nrow = 2)

PLOT

ggsave("~/Nextcloud/project-fab-forschung/Publikationen/FLOA/tex/Grafiken/difference_intervals.png", device = "png", dpi = 300)
```


```{r echo = FALSE, warning = FALSE, message = FALSE}
# Realistic smooth wave data (constant variance, no trend)
data <- example_data(dat = "smooth_realistic", dir.data)

# Leave-one curve out approach
cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)

# Calculate percent from counts
calculate_percent <- function(data) {
  percentage <- (sum(data) / length(data))
  percentage <- round(percentage, digits = 2)
}

covered.curves.percent <- apply(cover.cross.singlecurve, 2, calculate_percent)
covered.curves.percent <- data.frame(t(covered.curves.percent))
colnames(covered.curves.percent) <- c("POINT", "ROISLIEN", "BOOT")

# Curves with non-gaussian (Weibull distributed) error (no trend)
data <- example_data(dat = "non_gaussian", dir.data)
cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)
covered.curves.percent <- rbind(covered.curves.percent, apply(cover.cross.singlecurve, 2, calculate_percent))

# Curves phase shifted in x-axis direction
data <- example_data(dat = "shift", dir.data)
cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)
covered.curves.percent <- rbind(covered.curves.percent, apply(cover.cross.singlecurve, 2, calculate_percent))

# Real-world validation data
data <- example_data(dat = "imu_mc", dir.data)
cover.cross.singlecurve <- singlecurve_coverage(data, n.boot)
covered.curves.percent <- rbind(covered.curves.percent, apply(cover.cross.singlecurve, 2, calculate_percent))


rownames(covered.curves.percent) <- c("A. GAUSS", "B. NONGAUSS", "C. XSHIFT", "D. REAL")

table.tmp <- knitr::kable(covered.curves.percent, caption = "Table 1: Percentages of entirely covered curves for methods POINT, ROISLIEN and BOOT across data sets A - D (A - Gaussian error model, B - Non-Gaussian errors and heteroskedasticity, C - Gaussian error model and phase shift in x-axis direction, D - Real-world hip joint angle curves). Coverage values are presented as mean values across $D = 110$ leave-one-out test curves.")

table.tmp

# writeLines(table.tmp, 'table1.tex')
```


```{r echo = FALSE, warning = FALSE, message = FALSE}
# Realistic smooth wave data (constant variance, no trend)
data <- example_data(dat = "smooth_realistic", dir.data)
n.strides <- length(unique(data$strideID))
# Leave-one curve out approach
cover.cross.fraction.singlecurve <- singlecurve_coverage_fraction(data, n.boot)
# Create list of numeric values for histogram
hist.list <- cover.cross.fraction.singlecurve
cover.cross.fraction.singlecurve <- cbind(cover.cross.fraction.singlecurve, rep("A. GAUSS", n.strides))
colnames(cover.cross.fraction.singlecurve) <- c("POINT", "ROISLIEN", "BOOT", "Data")


# Curves with non-gaussian (Weibull distributed) error (no trend)
data <- example_data(dat = "non_gaussian", dir.data)
tmp <- singlecurve_coverage_fraction(data, n.boot)
hist.list <- cbind(hist.list, tmp)
cover.cross.fraction.singlecurve <- rbind(cover.cross.fraction.singlecurve, cbind(tmp, rep("B. NONGAUSS", n.strides)))

hist.list <- cbind(hist.list, tmp)

# Curves phase shifted in x-axis direction
data <- example_data(dat = "shift", dir.data)
tmp <- singlecurve_coverage_fraction(data, n.boot)
hist.list <- cbind(hist.list, tmp)
cover.cross.fraction.singlecurve <- rbind(cover.cross.fraction.singlecurve, cbind(tmp, rep("C. XSHIFT", n.strides)))

# Real-world validation data
data <- example_data(dat = "imu_mc", dir.data)
tmp <- singlecurve_coverage_fraction(data, n.boot)
hist.list <- cbind(hist.list, tmp)
cover.cross.fraction.singlecurve <- rbind(cover.cross.fraction.singlecurve, cbind(tmp, rep("D. REAL", n.strides)))

# Melt data to long format
# Assign correct class to avoid problems when melting to long data format
cover.cross.fraction.singlecurve <- data.frame(cover.cross.fraction.singlecurve)
cover.cross.fraction.singlecurve$POINT <- as.numeric(cover.cross.fraction.singlecurve$POINT)
cover.cross.fraction.singlecurve$ROISLIEN <- as.numeric(cover.cross.fraction.singlecurve$ROISLIEN)
cover.cross.fraction.singlecurve$BOOT <- as.numeric(cover.cross.fraction.singlecurve$BOOT)

cover.cross.fraction.singlecurve.melt <- reshape2::melt(cover.cross.fraction.singlecurve)
names(cover.cross.fraction.singlecurve.melt)[2] <- "Method"

# Create a table with historgrams and boxplots
# https://vincentarelbundock.github.io/modelsummary/articles/datasummary.html#histograms-1
library(modelsummary)
library(kableExtra)

# Create a list with individual variables
tmp_list <- list(hist.list)
# tmp_list <- list(sample(10), sample(10), sample(10), sample(10), sample(10), sample(10))

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# emptycol = function(x) " "
caption <- "Table 2: Proportion of covered points across the curve. Due to the highly skewed distribution of coverage values (most values close to 1), the distribution of coverage values across $D = 110$ leave-one-out test curves is summarized using median, mode and range variables (minimum and maximum)."
datasummary(Data * (Method * Heading("") * value) ~ Min + Max + Median + Mode, data = cover.cross.fraction.singlecurve.melt, title = caption)
# + Heading("Histogram") * emptycol
# %>%
  # column_spec(column = 7, image = spec_hist(tmp_list))

```


```{r echo = FALSE, warning = FALSE, message = FALSE}
data <- example_data(dat = "smooth_realistic", dir.data)
uncertainty <- estimate_uncertainty_loa(data, n.boot)

# Curves with non-gaussian (Weibull distributed) error (no trend)
data <- example_data(dat = "non_gaussian", dir.data)
NONGAUSS <- estimate_uncertainty_loa(data, n.boot)
uncertainty <- rbind(uncertainty, NONGAUSS)

# Curves phase shifted in x-axis direction
data <- example_data(dat = "shift", dir.data)
XSHIFT <- estimate_uncertainty_loa(data, n.boot)
uncertainty <- rbind(uncertainty, XSHIFT)

# Real-world validation data
data <- example_data(dat = "imu_mc", dir.data)
REAL <- estimate_uncertainty_loa(data, n.boot)
uncertainty <- rbind(uncertainty, REAL)

# Adjust column order and column/row names for the use in tables
rownames(uncertainty) <- c("GAUSS", "NONGAUSS", "XSHIFT", "REAL")
# colnames(uncertainty) <- c("POINT", "ROISLIEN", "BOOT")

knitr::kable(uncertainty, caption = "Table 3: Cumulated Uncertainty Area. Values are displayed separately for the upper (U) and lower (L) limits of the three methods: POINT, ROISLIEN, BOOT. POINT values are identical for the upper and lower limits as symmetric confidence intervals were calculated.")
```

# Discussion
Die Tatsache, dass ein erheblicher Teil biomechanischer Messsysteme höherdimensionale Daten (> 0D) liefert, spiegelt sich bislang kaum in der Methodik von Validierungsstudien wieder. Um die Aussagekraft von Validierungsuntersuchungen diesbezüglich zu erhöhen, braucht es Fehlerintervalle, die alle Punkte eines Messsignals berücksichtigen. Zu diesem Zweck wurden im vorliegenden Paper drei relevante Verfahren zur Berechnung kontinuierlicher Fehlerbänder identifiziert (POINT, ROISLIEN, BOOT) und für ausgewählte Messfehlerszenarien am Beispiel von 1D Kurvendaten analysiert. BOOT ist ein funktionales Verfahren in dem diskrete Kurven mit mathematischen Funktionen approximiert werden und alle weiteren Berechnungen anhand dieser funktionalen Objekten vorgenommen werden. Die ROISLIEN-Methode wurde als funktionales Verfahren entwickelt, muss aber strenggenommen zu den punktweisen Verfahren gezählt werden, da die eigentliche Berechnung der Intervallgrenzen separat für jeden Messzeitpunkt erfolgt.

# Punktweise vs. funktionale Prädiktionsbänder
Die Intervalle der BOOT-Methode erreichen in allen untersuchten Szenarien die nominale coverage und sind mit weniger estimation uncertainty belastet als die beiden übrigen Verfahren (POINT, ROISLIEN). Dies ist insofern zu erwarten, als dass die BOOT-Bänder anhand eines Korrekturfaktors auf das nominale Niveau optimiert werden. Dies ist ein wesentlicher Unterschied zu den parametrischen POINT und ROISLIEN Methoden, bei denen die Intervallgrenzen auf Grundlage der Verteilung der Differenzen in der Stichprobe geschätzt werden.

Die punktweise berechneten Bänder fallen erwartungsgemäß enger aus als die funktionalen BOOT-Bänder (Figure 2, Table 1 & 2). Die coverage der punktweise konstruierten Bänder ist dennoch ausgezeichnet wenn man den Anteil der abgedeckten Punkte pro Kurve über alle $D = 110$ Iterationen der leave-one-out Kreuzvalidierung als Bewertungsgrundlage nimmt. Die zugehörige Verteilung ist extrem linksschief, d. h. bis auf wenige Ausnahmen liegen stets nahezu alle Punkte der Testkurven im trainierten Prädiktionsintervall.

Die Verläufe der Intervallgrenzen im POINT und ROISLIEN-Verfahren Verfahren sind qualitativ ähnlich, die coverage (Table 1 & 2) ist beim ROISLIEN-Verfahren jedoch etwas niedriger. Die Ursache hierfür liegt in der höheren Streuung der ROISLIEN-Intervallgrenzen, da hier nur jeweils eine Kurve pro Proband gezogen wird und kleinere Stichproben generell einer größeren Unsicherheit unterliegen. Bei der POINT-Methode hingegen werden stets alle Kurven im Datensatz berücksichtigt. Um der prinzipiellen Unsicherheit von Samplingprozessen Rechnung zu tragen, empfehlen Bland & Altman die Erweiterung der LoA um Konfidenzbänder. Dieser Vorschlag führt die ursprüngliche Idee einfach zu berechnender, intuitiver Unsicherheitsintervalle allerdings ein Stück weit ad absurdum (Francq et al., 2020), weshalb in der vorliegenden Arbeit auf eine Verbreiterung der LoA durch Konfidenzbänder verzichtet wurde. Ohnehin ist die korrekte Umsetzung der POINT-Methode nach Bland & Altman (1999) (mit Varianzanteilen aus einer ANOVA mit Messwiederholung etc.) deutlich komplexer als das im ROISLEN-Verfahren eingesetzte minimale Bland & Altman Modell ($\overline{d} \pm 1.96SD$). Dadurch fällt auch der eigentliche Vorteil punktweiser Intervalle gegenüber funktionalen Verfahren - die Einfachheit der Berechnung - erheblich geringer aus.

Die punktweisen Verfahren liefern auch für die Datensätze weitgehend plausible Verläufe, in denen erhebliche Verletzungen der parametrischen Modellannahmen vorliegen (nicht-gaussverteilten Differenzen, phase shift in x-axis direction). Für die Praxis ist das eine wichtige Erkenntnis, da diese Annahmen in vielen Fällen verletzt sind, z. B. wenn Sensorwerte wegen einer Begrenzung des Messbereichs oder zu geringer Auflösung abgeschnitten werden, oder in Gegenwart von nichtlinearem Drift. Speziell im letzteren Fall sind Alternativen zum BOOT-Verfahren von Interesse, da die Methode nur für stationäre Signale zuverlässig funktioniert (Lenhoff et al., 1999). Das punktweise Vorgehen hat darüber hinaus einen Vorteil gegenüber funktionalen Verfahren wenn die untersuchten Kurven weniger glatt sind als in den hier untersuchten Beispieldatensätzen (z. B. EMG-Signale) weil das Fitten mathematischer Funktionen für diese Art Kurven nicht immer möglich ist. Praktisch gibt es aber nur wenige Signale bei denen das wirklich zum Tragen kommt: In den meisten Fällen werden verrauschte Signale (z. B. Beschleunigungssignale) ohnehin tiefpassgefiltert, so dass man auch im Rahmen der Validierung von glatten Kurven ausgehen kann. Eine genauere Analyse derartiger Kurven sprengt zudem den Rahmen dieser Arbeit.

#### Konstruktion und Auswahl geeigneter Fehlerbänder
Primäres Ziel des vorliegenden Papers war es Unterschiede zwischen kontinuierlichen und punktweisen Verfahren mit Blick auf die Konstruktion von Fehlerintervallen in Methodenvergleichen zu analysieren. Das am häufigsten genutze Tool in Methodenvergleichen ist das im medizinischen Kontext entwickelte Bland & Altman Verfahren, mit dem der Grad der Übereinstimmung anhand von Differenzen zwischen zwei Messsystemen bewertet wird. Die entsprechenden LoA fallen verhältnismäßig breit aus weil sie einen hohen Anteil (95%) der Einzelbeobachtungen enthalten sollten um eine gewisse Sicherheit zu haben, dass auch die nächste Einzelmessung im Intervall liegt. Im biomechanischen Kontext ist das z. B. dann relevant, wenn neue Messwerte mit normativen Daten (z. B. aus einer Referenzdatenbank) verglichen werden. Wenn die Abweichung ein bestimmtes Maß überschreitet, d. h. der Proband nicht zur Referenzpopulation gehört, können z. B. pathologische Muster angenommen werden (Olshen et al., 1989). Dabei ist von Bedeutung, dass die Bänder nicht zu eng ausfallen, weil die Konsequenzen falsch positiver Schlüsse schwerwiegend sein können.

Für viele andere Fragestellungen sind Prädiktionsintervalle allerdings eher ungeeignet, weil breitere Intervalle ein höheres Risiko für falsch negative Schlüsse bedeuten. Das ist u. a. dann der Fall, wenn die Messwerte im Kontext eines Vergleichs verschiedener Probandenkollektive erhoben werden (z. B. in Interventionsstudien oder case-control Studien). Gut demonstrieren lässt sich das am Beispiel des realweltlichen Datensatzes in Fig. 2 D (Differenzen (IMU - MC) sagittaler Hüftwinkel): Ein mittels IMU gemessener Unterschied zwischen den sagittalen Hüftwinkeln z. B. einer Kontroll- und Interventionsgruppe kann hier nur dann als tatsächlicher Effekt angenommen werden, wenn die Differenz außerhalb der ermittelten Intervallgrenzen von ca. $\pm$ 10° liegt. Derartig große Effekte sind in biomechanischen Untersuchungen allerdings nur selten zu erwarten (Knudson, 2017). Die Streuung der Differenzen im Beispiel ist dabei längst kein unrealistisches Szenario. Gerade bei markerbasierten motion capture Systemen, die häufig als Referenz in Methodenvergleichen eingesetzt werden, ist die Reliabilität aufgrund von z. B. Weichteilbewegungen oder Markerplatzierungsartefakten limitiert (McGinley et al., 2009), so dass hier ohne Weiteres sehr breite (Prädiktions)Intervalle entstehen können.

Eine Alternative zu den breiten Prädiktionsintervallen sind Intervalle auf Grundlage der within-subject Standardabweichung (Bland & Altman, 1999). Bei den Hüftgelenksdifferenzen (Fig. 2, D) lässt sich erkennen, dass die Streuung innerhalb einzelner Probanden erheblich geringer ausfällt (erkennbar an den probandenweisen Kurvenclustern). Diese Eigenschaft kann ausgenutzt werden um engere Intervalle auf Grundlage der intraindividuellen Streuung zu konstruieren wenn primär die Reproduzierbarkeit der neuen Methode von Bedeutung ist. Das ist z. B. von Interesse wenn Untersuchungen mit einem reinen within-subjects Design durchgeführt werden (z. B. intraindividuelle bei prä-post-Vergleiche). Neben der Tatsache dass diese Intervalle bereits für sich gesehen informativ sind, stellen sie auch eine Art Baseline zur Bewertung der between-method variability dar (Bland & Altman, 1999). Was leider keines der vorgestellten Verfahren vorsieht ist die Möglichkeit asymmetrischer Bänder um Unterschiede in der Ausprägung des zufälligen Messfehlers abzubilden. Vorstellbar wäre z. B. eine Methode in der anstatt der symmetrischen um einen zentralen Wert Perzentile als Intervallgrenzen definiert werden. Interessant erscheint auch der Ansatz diese Intervallgrenzen (ähnlich wie in BOOT) auf eine bestimmte coverage probability hin zu korrigieren.

In den Fällen wo Messsysteme zunächst ohne klar definiertes Anwendungsgebiet validiert werden, empfehlen wir verschiedene Bänder für within und between-subject Designs zu konstruieren. Punktweise konstruierte Bänder stellen hierbei eine brauchbare Alternative dar. Hier sollten aber das in dieser Arbeit implementierte, komplexere Modell mit Messwiederholungen berücksichtigt werden um keine zu engen Intervallgrenzen zu erhalten. In jedem Fall aber sollten aus den in der Einleitung aufgeführten Gründen kontinuierliche Methoden den Vorzug gegenüber diskreten Verfahren erhalten. Wir spekulieren dass der spärliche Einsatz kontinuierlicher Verfahren in direktem Zusammenhang mit der Komplexität der Verfahren steht, die vermutlich eine hohe Hürde für viele Forscher mit weniger ausgeprägten Statistik- und Programmierkenntnissen darstellt. Um die Verbreitung kontinuierlicher Methoden zu katalysieren stellen wir daher die bei der Erstellung des Papers implementierten Methoden als R Code im Anhang und zusätzlich (inkl. aller Datensätze) auf Github zur Verfügung (https://github.com/koda86/floa). 

# Conclusion
Punktweise Intervalle auf Grundlage parameterischer Modelle können durchaus brauchbare Ergebnisse liefern, auch bei Daten in denen die Voraussetzungen mitunter eheblich verletzt sind. ... Voraussetzung ist das sie in geeigneter Weise berechnet werden ... Dazu zählt u. a. die Berücksichtigung von messwiederholten Daten ... man könnte auch wie bei Lenhoff einen Korrekturfaktor reinbringen

